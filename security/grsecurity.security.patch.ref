diff --git a/security/Kconfig b/security/Kconfig
index 118f454..3312d82 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -4,6 +4,1066 @@

 menu "Security options"

+menu "Grsecurity"
+
+config ARCH_TRACK_EXEC_LIMIT
+	bool
+
+config PAX_PER_CPU_PGD
+	bool
+
+config TASK_SIZE_MAX_SHIFT
+	int
+	depends on X86_64
+	default 47 if !PAX_PER_CPU_PGD
+	default 42 if PAX_PER_CPU_PGD
+
+config PAX_ENABLE_PAE
+	bool
+	default y if (X86_32 && (MPENTIUM4 || MK8 || MPSC || MCORE2 || MATOM))
+
+config GRKERNSEC
+	bool "Grsecurity"
+	select CRYPTO
+	select CRYPTO_SHA256
+	select PROC_FS
+	select STOP_MACHINE
+	select TTY
+	select DEBUG_KERNEL
+	select DEBUG_LIST
+	select MULTIUSER
+	select BUG
+	help
+	  If you say Y here, you will be able to configure many features
+	  that will enhance the security of your system.  It is highly
+	  recommended that you say Y here and read through the help
+	  for each option so that you fully understand the features and
+	  can evaluate their usefulness for your machine.
+
+choice
+	prompt "Configuration Method"
+	depends on GRKERNSEC
+	default GRKERNSEC_CONFIG_CUSTOM
+	help
+
+config GRKERNSEC_CONFIG_AUTO
+	bool "Automatic"
+	help
+	  If you choose this configuration method, you'll be able to answer a small
+	  number of simple questions about how you plan to use this kernel.
+	  The settings of grsecurity and PaX will be automatically configured for
+	  the highest commonly-used settings within the provided constraints.
+
+	  If you require additional configuration, custom changes can still be made
+	  from the "custom configuration" menu.
+
+config GRKERNSEC_CONFIG_CUSTOM
+	bool "Custom"
+	help
+	  If you choose this configuration method, you'll be able to configure all
+	  grsecurity and PaX settings manually.  Via this method, no options are
+	  automatically enabled.
+
+	  Take note that if menuconfig is exited with this configuration method
+	  chosen, you will not be able to use the automatic configuration methods
+	  without starting again with a kernel configuration with no grsecurity
+	  or PaX options specified inside.
+
+endchoice
+
+choice
+	prompt "Usage Type"
+	depends on (GRKERNSEC && GRKERNSEC_CONFIG_AUTO)
+	default GRKERNSEC_CONFIG_SERVER
+	help
+
+config GRKERNSEC_CONFIG_SERVER
+	bool "Server"
+	help
+	  Choose this option if you plan to use this kernel on a server.
+
+config GRKERNSEC_CONFIG_DESKTOP
+	bool "Desktop"
+	help
+	  Choose this option if you plan to use this kernel on a desktop.
+
+endchoice
+
+choice
+	prompt "Virtualization Type"
+	depends on (GRKERNSEC && X86 && GRKERNSEC_CONFIG_AUTO)
+	default GRKERNSEC_CONFIG_VIRT_NONE
+	help
+
+config GRKERNSEC_CONFIG_VIRT_NONE
+	bool "None"
+	help
+	  Choose this option if this kernel will be run on bare metal.
+
+config GRKERNSEC_CONFIG_VIRT_GUEST
+	bool "Guest"
+	help
+	  Choose this option if this kernel will be run as a VM guest.
+
+config GRKERNSEC_CONFIG_VIRT_HOST
+	bool "Host"
+	help
+	  Choose this option if this kernel will be run as a VM host.
+
+endchoice
+
+choice
+	prompt "Virtualization Hardware"
+	depends on (GRKERNSEC && X86 && GRKERNSEC_CONFIG_AUTO && (GRKERNSEC_CONFIG_VIRT_GUEST || GRKERNSEC_CONFIG_VIRT_HOST))
+	help
+
+config GRKERNSEC_CONFIG_VIRT_EPT
+	bool "EPT/RVI Processor Support"
+	depends on X86
+	help
+	  Choose this option if your CPU supports the EPT or RVI features of 2nd-gen
+	  hardware virtualization.  This allows for additional kernel hardening protections
+	  to operate without additional performance impact.
+
+	  To see if your Intel processor supports EPT, see:
+	  http://ark.intel.com/Products/VirtualizationTechnology
+	  (Most Core i3/5/7 support EPT)
+
+	  To see if your AMD processor supports RVI, see:
+	  http://support.amd.com/us/kbarticles/Pages/GPU120AMDRVICPUsHyperVWin8.aspx
+
+config GRKERNSEC_CONFIG_VIRT_SOFT
+	bool "First-gen/No Hardware Virtualization"
+	help
+	  Choose this option if you use an Atom/Pentium/Core 2 processor that either doesn't
+	  support hardware virtualization or doesn't support the EPT/RVI extensions.
+
+endchoice
+
+choice
+	prompt "Virtualization Software"
+	depends on (GRKERNSEC && GRKERNSEC_CONFIG_AUTO && (GRKERNSEC_CONFIG_VIRT_GUEST || GRKERNSEC_CONFIG_VIRT_HOST))
+	help
+
+config GRKERNSEC_CONFIG_VIRT_XEN
+	bool "Xen"
+	help
+	  Choose this option if this kernel is running as a Xen guest or host.
+
+config GRKERNSEC_CONFIG_VIRT_VMWARE
+	bool "VMWare"
+	help
+	  Choose this option if this kernel is running as a VMWare guest or host.
+
+config GRKERNSEC_CONFIG_VIRT_KVM
+	bool "KVM"
+	help
+	  Choose this option if this kernel is running as a KVM guest or host.
+
+config GRKERNSEC_CONFIG_VIRT_VIRTUALBOX
+	bool "VirtualBox"
+	help
+	  Choose this option if this kernel is running as a VirtualBox guest or host.
+
+config GRKERNSEC_CONFIG_VIRT_HYPERV
+	bool "Hyper-V"
+	help
+	  Choose this option if this kernel is running as a Hyper-V guest.
+
+endchoice
+
+choice
+	prompt "Required Priorities"
+	depends on (GRKERNSEC && GRKERNSEC_CONFIG_AUTO)
+	default GRKERNSEC_CONFIG_PRIORITY_PERF
+	help
+
+config GRKERNSEC_CONFIG_PRIORITY_PERF
+	bool "Performance"
+	help
+	  Choose this option if performance is of highest priority for this deployment
+	  of grsecurity.  Features like UDEREF on a 64bit kernel, kernel stack clearing,
+	  clearing of structures intended for userland, and freed memory sanitizing will
+	  be disabled.
+
+config GRKERNSEC_CONFIG_PRIORITY_SECURITY
+	bool "Security"
+	help
+	  Choose this option if security is of highest priority for this deployment of
+	  grsecurity.  UDEREF, kernel stack clearing, clearing of structures intended
+	  for userland, and freed memory sanitizing will be enabled for this kernel.
+	  In a worst-case scenario, these features can introduce a 20% performance hit
+	  (UDEREF on x64 contributing half of this hit).
+
+endchoice
+
+menu "Default Special Groups"
+depends on (GRKERNSEC && GRKERNSEC_CONFIG_AUTO)
+
+config GRKERNSEC_PROC_GID
+	int "GID exempted from /proc restrictions"
+	default 1001
+	help
+	  Setting this GID determines which group will be exempted from
+	  grsecurity's /proc restrictions, allowing users of the specified
+	  group  to view network statistics and the existence of other users'
+	  processes on the system.  This GID may also be chosen at boot time
+	  via "grsec_proc_gid=" on the kernel commandline.
+
+config GRKERNSEC_TPE_UNTRUSTED_GID
+        int "GID for TPE-untrusted users"
+        depends on GRKERNSEC_CONFIG_SERVER && GRKERNSEC_TPE && !GRKERNSEC_TPE_INVERT
+        default 1005
+        help
+	  Setting this GID determines which group untrusted users should
+	  be added to.  These users will be placed under grsecurity's Trusted Path
+	  Execution mechanism, preventing them from executing their own binaries.
+	  The users will only be able to execute binaries in directories owned and
+	  writable only by the root user.  If the sysctl option is enabled, a sysctl
+	  option with name "tpe_gid" is created.
+
+config GRKERNSEC_TPE_TRUSTED_GID
+        int "GID for TPE-trusted users"
+        depends on GRKERNSEC_CONFIG_SERVER && GRKERNSEC_TPE && GRKERNSEC_TPE_INVERT
+        default 1005
+        help
+          Setting this GID determines what group TPE restrictions will be
+          *disabled* for.  If the sysctl option is enabled, a sysctl option
+          with name "tpe_gid" is created.
+
+config GRKERNSEC_SYMLINKOWN_GID
+        int "GID for users with kernel-enforced SymlinksIfOwnerMatch"
+        depends on GRKERNSEC_CONFIG_SERVER
+        default 1006
+        help
+          Setting this GID determines what group kernel-enforced
+          SymlinksIfOwnerMatch will be enabled for.  If the sysctl option
+          is enabled, a sysctl option with name "symlinkown_gid" is created.
+
+
+endmenu
+
+menu "Customize Configuration"
+depends on GRKERNSEC
+
+menu "PaX"
+
+config PAX
+	bool "Enable various PaX features"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on GRKERNSEC && (ALPHA || ARM || AVR32 || IA64 || MIPS || PARISC || PPC || SPARC || X86)
+	help
+	  This allows you to enable various PaX features.  PaX adds
+	  intrusion prevention mechanisms to the kernel that reduce
+	  the risks posed by exploitable memory corruption bugs.
+
+menu "PaX Control"
+	depends on PAX
+
+config PAX_SOFTMODE
+	bool 'Support soft mode'
+	help
+	  Enabling this option will allow you to run PaX in soft mode, that
+	  is, PaX features will not be enforced by default, only on executables
+	  marked explicitly.  You must also enable PT_PAX_FLAGS or XATTR_PAX_FLAGS
+	  support as they are the only way to mark executables for soft mode use.
+
+	  Soft mode can be activated by using the "pax_softmode=1" kernel command
+	  line option on boot.  Furthermore you can control various PaX features
+	  at runtime via the entries in /proc/sys/kernel/pax.
+
+config PAX_EI_PAX
+	bool 'Use legacy ELF header marking'
+	default y if GRKERNSEC_CONFIG_AUTO
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'chpax' utility available at
+	  http://pax.grsecurity.net/.  The control flags will be read from
+	  an otherwise reserved part of the ELF header.  This marking has
+	  numerous drawbacks (no support for soft-mode, toolchain does not
+	  know about the non-standard use of the ELF header) therefore it
+	  has been deprecated in favour of PT_PAX_FLAGS and XATTR_PAX_FLAGS
+	  support.
+
+	  Note that if you enable PT_PAX_FLAGS or XATTR_PAX_FLAGS marking
+	  support as well, they will override the legacy EI_PAX marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+config PAX_PT_PAX_FLAGS
+	bool 'Use ELF program header marking'
+	default y if GRKERNSEC_CONFIG_AUTO
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'paxctl' utility available at
+	  http://pax.grsecurity.net/.  The control flags will be read from
+	  a PaX specific ELF program header (PT_PAX_FLAGS).  This marking
+	  has the benefits of supporting both soft mode and being fully
+	  integrated into the toolchain (the binutils patch is available
+	  from http://pax.grsecurity.net).
+
+	  Note that if you enable the legacy EI_PAX marking support as well,
+	  the EI_PAX marks will be overridden by the PT_PAX_FLAGS marks.
+
+	  If you enable both PT_PAX_FLAGS and XATTR_PAX_FLAGS support then you
+	  must make sure that the marks are the same if a binary has both marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+config PAX_XATTR_PAX_FLAGS
+	bool 'Use filesystem extended attributes marking'
+	default y if GRKERNSEC_CONFIG_AUTO
+	select CIFS_XATTR if CIFS
+	select EXT2_FS_XATTR if EXT2_FS
+	select EXT3_FS_XATTR if EXT3_FS
+	select F2FS_FS_XATTR if F2FS_FS
+	select JFFS2_FS_XATTR if JFFS2_FS
+	select REISERFS_FS_XATTR if REISERFS_FS
+	select SQUASHFS_XATTR if SQUASHFS
+	select TMPFS_XATTR if TMPFS
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'setfattr' utility.  The control
+	  flags will be read from the user.pax.flags extended attribute of
+	  the file.  This marking has the benefit of supporting binary-only
+	  applications that self-check themselves (e.g., skype) and would
+	  not tolerate chpax/paxctl changes.  The main drawback is that
+	  extended attributes are not supported by some filesystems (e.g.,
+	  isofs, udf, vfat) so copying files through such filesystems will
+	  lose the extended attributes and these PaX markings.
+
+	  Note that if you enable the legacy EI_PAX marking support as well,
+	  the EI_PAX marks will be overridden by the XATTR_PAX_FLAGS marks.
+
+	  If you enable both PT_PAX_FLAGS and XATTR_PAX_FLAGS support then you
+	  must make sure that the marks are the same if a binary has both marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+choice
+	prompt 'MAC system integration'
+	default PAX_HAVE_ACL_FLAGS
+	help
+	  Mandatory Access Control systems have the option of controlling
+	  PaX flags on a per executable basis, choose the method supported
+	  by your particular system.
+
+	  - "none": if your MAC system does not interact with PaX,
+	  - "direct": if your MAC system defines pax_set_initial_flags() itself,
+	  - "hook": if your MAC system uses the pax_set_initial_flags_func callback.
+
+	  NOTE: this option is for developers/integrators only.
+
+	config PAX_NO_ACL_FLAGS
+		bool 'none'
+
+	config PAX_HAVE_ACL_FLAGS
+		bool 'direct'
+
+	config PAX_HOOK_ACL_FLAGS
+		bool 'hook'
+endchoice
+
+endmenu
+
+menu "Non-executable pages"
+	depends on PAX
+
+config PAX_NOEXEC
+	bool "Enforce non-executable pages"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on ALPHA || (ARM && (CPU_V6 || CPU_V6K || CPU_V7)) || IA64 || MIPS || PARISC || PPC || S390 || SPARC || X86
+	help
+	  By design some architectures do not allow for protecting memory
+	  pages against execution or even if they do, Linux does not make
+	  use of this feature.  In practice this means that if a page is
+	  readable (such as the stack or heap) it is also executable.
+
+	  There is a well known exploit technique that makes use of this
+	  fact and a common programming mistake where an attacker can
+	  introduce code of his choice somewhere in the attacked program's
+	  memory (typically the stack or the heap) and then execute it.
+
+	  If the attacked program was running with different (typically
+	  higher) privileges than that of the attacker, then he can elevate
+	  his own privilege level (e.g. get a root shell, write to files for
+	  which he does not have write access to, etc).
+
+	  Enabling this option will let you choose from various features
+	  that prevent the injection and execution of 'foreign' code in
+	  a program.
+
+	  This will also break programs that rely on the old behaviour and
+	  expect that dynamically allocated memory via the malloc() family
+	  of functions is executable (which it is not).  Notable examples
+	  are the XFree86 4.x server, the java runtime and wine.
+
+config PAX_PAGEEXEC
+	bool "Paging based non-executable pages"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on PAX_NOEXEC && (!X86_32 || M586 || M586TSC || M586MMX || M686 || MPENTIUMII || MPENTIUMIII || MPENTIUMM || MCORE2 || MATOM || MPENTIUM4 || MPSC || MK7 || MK8 || MWINCHIPC6 || MWINCHIP2 || MWINCHIP3D || MVIAC3_2 || MVIAC7)
+	select ARCH_TRACK_EXEC_LIMIT if X86_32
+	help
+	  This implementation is based on the paging feature of the CPU.
+	  On i386 without hardware non-executable bit support there is a
+	  variable but usually low performance impact, however on Intel's
+	  P4 core based CPUs it is very high so you should not enable this
+	  for kernels meant to be used on such CPUs.
+
+	  On alpha, avr32, ia64, parisc, sparc, sparc64, x86_64 and i386
+	  with hardware non-executable bit support there is no performance
+	  impact, on ppc the impact is negligible.
+
+	  Note that several architectures require various emulations due to
+	  badly designed userland ABIs, this will cause a performance impact
+	  but will disappear as soon as userland is fixed. For example, ppc
+	  userland MUST have been built with secure-plt by a recent toolchain.
+
+config PAX_SEGMEXEC
+	bool "Segmentation based non-executable pages"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on PAX_NOEXEC && X86_32
+	help
+	  This implementation is based on the segmentation feature of the
+	  CPU and has a very small performance impact, however applications
+	  will be limited to a 1.5 GB address space instead of the normal
+	  3 GB.
+
+config PAX_EMUTRAMP
+	bool "Emulate trampolines"
+	default y if PARISC || GRKERNSEC_CONFIG_AUTO
+	depends on (PAX_PAGEEXEC || PAX_SEGMEXEC) && (PARISC || X86)
+	help
+	  There are some programs and libraries that for one reason or
+	  another attempt to execute special small code snippets from
+	  non-executable memory pages.  Most notable examples are the
+	  signal handler return code generated by the kernel itself and
+	  the GCC trampolines.
+
+	  If you enabled CONFIG_PAX_PAGEEXEC or CONFIG_PAX_SEGMEXEC then
+	  such programs will no longer work under your kernel.
+
+	  As a remedy you can say Y here and use the 'chpax' or 'paxctl'
+	  utilities to enable trampoline emulation for the affected programs
+	  yet still have the protection provided by the non-executable pages.
+
+	  On parisc you MUST enable this option and EMUSIGRT as well, otherwise
+	  your system will not even boot.
+
+	  Alternatively you can say N here and use the 'chpax' or 'paxctl'
+	  utilities to disable CONFIG_PAX_PAGEEXEC and CONFIG_PAX_SEGMEXEC
+	  for the affected files.
+
+	  NOTE: enabling this feature *may* open up a loophole in the
+	  protection provided by non-executable pages that an attacker
+	  could abuse.  Therefore the best solution is to not have any
+	  files on your system that would require this option.  This can
+	  be achieved by not using libc5 (which relies on the kernel
+	  signal handler return code) and not using or rewriting programs
+	  that make use of the nested function implementation of GCC.
+	  Skilled users can just fix GCC itself so that it implements
+	  nested function calls in a way that does not interfere with PaX.
+
+config PAX_EMUSIGRT
+	bool "Automatically emulate sigreturn trampolines"
+	depends on PAX_EMUTRAMP && PARISC
+	default y
+	help
+	  Enabling this option will have the kernel automatically detect
+	  and emulate signal return trampolines executing on the stack
+	  that would otherwise lead to task termination.
+
+	  This solution is intended as a temporary one for users with
+	  legacy versions of libc (libc5, glibc 2.0, uClibc before 0.9.17,
+	  Modula-3 runtime, etc) or executables linked to such, basically
+	  everything that does not specify its own SA_RESTORER function in
+	  normal executable memory like glibc 2.1+ does.
+
+	  On parisc you MUST enable this option, otherwise your system will
+	  not even boot.
+
+	  NOTE: this feature cannot be disabled on a per executable basis
+	  and since it *does* open up a loophole in the protection provided
+	  by non-executable pages, the best solution is to not have any
+	  files on your system that would require this option.
+
+config PAX_MPROTECT
+	bool "Restrict mprotect()"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on (PAX_PAGEEXEC || PAX_SEGMEXEC)
+	help
+	  Enabling this option will prevent programs from
+	   - changing the executable status of memory pages that were
+	     not originally created as executable,
+	   - making read-only executable pages writable again,
+	   - creating executable pages from anonymous memory,
+	   - making read-only-after-relocations (RELRO) data pages writable again.
+
+	  You should say Y here to complete the protection provided by
+	  the enforcement of non-executable pages.
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control
+	  this feature on a per file basis.
+
+config PAX_MPROTECT_COMPAT
+	bool "Use legacy/compat protection demoting (read help)"
+	depends on PAX_MPROTECT
+	default n
+	help
+	  The current implementation of PAX_MPROTECT denies RWX allocations/mprotects
+	  by sending the proper error code to the application.  For some older
+	  userland, this can cause problems with applications that assume such
+	  allocations will not be prevented by PaX or SELinux and other access
+	  control systems and have no fallback mechanisms.  For modern distros,
+	  this option should generally be set to 'N'.
+
+config PAX_ELFRELOCS
+	bool "Allow ELF text relocations (read help)"
+	depends on PAX_MPROTECT
+	default n
+	help
+	  Non-executable pages and mprotect() restrictions are effective
+	  in preventing the introduction of new executable code into an
+	  attacked task's address space.  There remain only two venues
+	  for this kind of attack: if the attacker can execute already
+	  existing code in the attacked task then he can either have it
+	  create and mmap() a file containing his code or have it mmap()
+	  an already existing ELF library that does not have position
+	  independent code in it and use mprotect() on it to make it
+	  writable and copy his code there.  While protecting against
+	  the former approach is beyond PaX, the latter can be prevented
+	  by having only PIC ELF libraries on one's system (which do not
+	  need to relocate their code).  If you are sure this is your case,
+	  as is the case with all modern Linux distributions, then leave
+	  this option disabled.  You should say 'n' here.
+
+config PAX_ETEXECRELOCS
+	bool "Allow ELF ET_EXEC text relocations"
+	depends on PAX_MPROTECT && (ALPHA || IA64 || PARISC)
+	select PAX_ELFRELOCS
+	default y
+	help
+	  On some architectures there are incorrectly created applications
+	  that require text relocations and would not work without enabling
+	  this option.  If you are an alpha, ia64 or parisc user, you should
+	  enable this option and disable it once you have made sure that
+	  none of your applications need it.
+
+config PAX_EMUPLT
+	bool "Automatically emulate ELF PLT"
+	depends on PAX_MPROTECT && (ALPHA || PARISC || SPARC)
+	default y
+	help
+	  Enabling this option will have the kernel automatically detect
+	  and emulate the Procedure Linkage Table entries in ELF files.
+	  On some architectures such entries are in writable memory, and
+	  become non-executable leading to task termination.  Therefore
+	  it is mandatory that you enable this option on alpha, parisc,
+	  sparc and sparc64, otherwise your system would not even boot.
+
+	  NOTE: this feature *does* open up a loophole in the protection
+	  provided by the non-executable pages, therefore the proper
+	  solution is to modify the toolchain to produce a PLT that does
+	  not need to be writable.
+
+config PAX_DLRESOLVE
+	bool 'Emulate old glibc resolver stub'
+	depends on PAX_EMUPLT && SPARC
+	default n
+	help
+	  This option is needed if userland has an old glibc (before 2.4)
+	  that puts a 'save' instruction into the runtime generated resolver
+	  stub that needs special emulation.
+
+config PAX_KERNEXEC
+	bool "Enforce non-executable kernel pages"
+	default y if GRKERNSEC_CONFIG_AUTO && (!X86 || GRKERNSEC_CONFIG_VIRT_NONE || (GRKERNSEC_CONFIG_VIRT_EPT && GRKERNSEC_CONFIG_VIRT_GUEST) || (GRKERNSEC_CONFIG_VIRT_EPT && GRKERNSEC_CONFIG_VIRT_KVM))
+	depends on (X86 || (ARM && (CPU_V6 || CPU_V6K || CPU_V7) && !(ARM_LPAE && MODULES))) && !XEN
+	select PAX_PER_CPU_PGD if X86_64 || (X86_32 && X86_PAE)
+	select ARM_KERNMEM_PERMS if ARM
+	help
+	  This is the kernel land equivalent of PAGEEXEC and MPROTECT,
+	  that is, enabling this option will make it harder to inject
+	  and execute 'foreign' code in kernel memory itself.
+
+	  Note that on amd64, CONFIG_EFI enabled with "efi=old_map" on
+	  the kernel command-line will result in an RWX physical map.
+
+	  Likewise, the EFI runtime services are necessarily mapped as
+	  RWX.  If CONFIG_EFI is enabled on an EFI-capable system, it
+	  is recommended that you boot with "noefi" on the kernel
+	  command-line if possible to eliminate the mapping.
+
+config PAX_KERNEXEC_PLUGIN
+	bool
+	depends on GCC_PLUGINS && X86_64
+
+choice
+	prompt "Code Pointer Instrumentation Method"
+	default PAX_KERNEXEC_PLUGIN_METHOD_BTS
+	depends on GCC_PLUGINS && X86_64 && (PAX_KERNEXEC || PAX_RAP)
+	help
+	  KERNEXEC on amd64 is not as secure as its i386 variant due to the
+	  lack of certain processor features. This option can bring back some
+	  of the security by forcing all code pointers at runtime to fall into
+	  kernel memory. This is achieved via compile time instrumentation of
+	  all code pointer dereferences (indirect calls and function returns).
+
+	  While there are alternative mechanisms (SMEP, UDEREF) that can achieve
+	  the same or even more, they also have their own drawbacks in terms of
+	  performance impact and/or being processor dependent so this feature
+	  offers a choice by having a low performance impact and being processor
+	  independent.
+
+	  If you enabled RAP (see PAX_RAP) and have an amd64 processor that does
+	  not support SMEP then you must also enable a KERNEXEC code pointer
+	  instrumentation method.
+
+	  Note that binary modules cannot be instrumented by this approach.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	config PAX_KERNEXEC_PLUGIN_METHOD_NONE
+		bool "none"
+		help
+		  In case your processor supports Supervisor Mode Execution
+		  Prevention (SMEP) you should choose this option to disable
+		  compile time instrumentation.
+
+		  Note that the kernel will refuse to boot if SMEP is not
+		  supported by the processor or is disabled on the kernel
+		  command line.
+
+	config PAX_KERNEXEC_PLUGIN_METHOD_BTS
+		bool "bts"
+		select PAX_KERNEXEC_PLUGIN
+		help
+		  This method is compatible with binary only modules but has
+		  a higher runtime overhead.
+
+	config PAX_KERNEXEC_PLUGIN_METHOD_OR
+		bool "or"
+		depends on !PARAVIRT
+		select PAX_KERNEXEC_PLUGIN
+		help
+		  This method is incompatible with binary only modules but has
+		  a lower runtime overhead.
+endchoice
+
+config PAX_KERNEXEC_MODULE_TEXT
+	int "Minimum amount of memory reserved for module code"
+	default "8" if (!GRKERNSEC_CONFIG_AUTO || GRKERNSEC_CONFIG_SERVER)
+	default "12" if (GRKERNSEC_CONFIG_AUTO && GRKERNSEC_CONFIG_DESKTOP)
+	depends on PAX_KERNEXEC && X86_32
+	help
+	  Due to implementation details the kernel must reserve a fixed
+	  amount of memory for runtime allocated code (such as modules)
+	  at compile time that cannot be changed at runtime.  Here you
+	  can specify the minimum amount in MB that will be reserved.
+	  Due to the same implementation details this size will always
+	  be rounded up to the next 2/4 MB boundary (depends on PAE) so
+	  the actually available memory for runtime allocated code will
+	  usually be more than this minimum.
+
+	  The default 4 MB should be enough for most users but if you have
+	  an excessive number of modules (e.g., most distribution configs
+	  compile many drivers as modules) or use huge modules such as
+	  nvidia's kernel driver, you will need to adjust this amount.
+	  A good rule of thumb is to look at your currently loaded kernel
+	  modules and add up their sizes.
+
+endmenu
+
+menu "Address Space Layout Randomization"
+	depends on PAX
+
+config PAX_ASLR
+	bool "Address Space Layout Randomization"
+	default y if GRKERNSEC_CONFIG_AUTO
+	help
+	  Many if not most exploit techniques rely on the knowledge of
+	  certain addresses in the attacked program.  The following options
+	  will allow the kernel to apply a certain amount of randomization
+	  to specific parts of the program thereby forcing an attacker to
+	  guess them in most cases.  Any failed guess will most likely crash
+	  the attacked program which allows the kernel to detect such attempts
+	  and react on them.  PaX itself provides no reaction mechanisms,
+	  instead it is strongly encouraged that you make use of grsecurity's
+	  (http://www.grsecurity.net/) built-in crash detection features or
+	  develop one yourself.
+
+	  By saying Y here you can choose to randomize the following areas:
+	   - top of the task's kernel stack
+	   - top of the task's userland stack
+	   - base address for mmap() requests that do not specify one
+	     (this includes all libraries)
+	   - base address of the main executable
+
+	  It is strongly recommended to say Y here as address space layout
+	  randomization has negligible impact on performance yet it provides
+	  a very effective protection.
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control
+	  this feature on a per file basis.
+
+config PAX_RANDKSTACK
+	bool "Randomize kernel stack base"
+	default y if GRKERNSEC_CONFIG_AUTO && !(GRKERNSEC_CONFIG_VIRT_HOST && GRKERNSEC_CONFIG_VIRT_VIRTUALBOX)
+	depends on X86_TSC && X86
+	help
+	  By saying Y here the kernel will randomize every task's kernel
+	  stack on every system call.  This will not only force an attacker
+	  to guess it but also prevent him from making use of possible
+	  leaked information about it.
+
+	  Since the kernel stack is a rather scarce resource, randomization
+	  may cause unexpected stack overflows, therefore you should very
+	  carefully test your system.  Note that once enabled in the kernel
+	  configuration, this feature cannot be disabled on a per file basis.
+
+config PAX_RANDUSTACK
+	bool
+
+config PAX_RANDMMAP
+	bool "Randomize user stack and mmap() bases"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on PAX_ASLR
+	select PAX_RANDUSTACK
+	help
+	  By saying Y here the kernel will randomize every task's userland
+	  stack and use a randomized base address for mmap() requests that
+	  do not specify one themselves.
+
+	  The stack randomization is done in two steps where the second
+	  one may apply a big amount of shift to the top of the stack and
+	  cause problems for programs that want to use lots of memory (more
+	  than 2.5 GB if SEGMEXEC is not active, or 1.25 GB when it is).
+
+	  As a result of mmap randomization all dynamically loaded libraries
+	  will appear at random addresses and therefore be harder to exploit
+	  by a technique where an attacker attempts to execute library code
+	  for his purposes (e.g. spawn a shell from an exploited program that
+	  is running at an elevated privilege level).
+
+	  Furthermore, if a program is relinked as a dynamic ELF file, its
+	  base address will be randomized as well, completing the full
+	  randomization of the address space layout.  Attacking such programs
+	  becomes a guess game.  You can find an example of doing this at
+	  http://pax.grsecurity.net/et_dyn.tar.gz and practical samples at
+	  http://www.grsecurity.net/grsec-gcc-specs.tar.gz .
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control this
+	  feature on a per file basis.
+
+endmenu
+
+menu "Miscellaneous hardening features"
+
+config PAX_MEMORY_SANITIZE
+	bool "Sanitize all freed memory"
+	default y if (GRKERNSEC_CONFIG_AUTO && GRKERNSEC_CONFIG_PRIORITY_SECURITY)
+	help
+	  By saying Y here the kernel will erase memory pages and slab objects
+	  as soon as they are freed.  This in turn reduces the lifetime of data
+	  stored in them, making it less likely that sensitive information such
+	  as passwords, cryptographic secrets, etc stay in memory for too long.
+
+	  This is especially useful for programs whose runtime is short, long
+	  lived processes and the kernel itself benefit from this as long as
+	  they ensure timely freeing of memory that may hold sensitive
+	  information.
+
+	  A nice side effect of the sanitization of slab objects is the
+	  reduction of possible info leaks caused by padding bytes within the
+	  leaky structures.  Use-after-free bugs for structures containing
+	  pointers can also be detected as dereferencing the sanitized pointer
+	  will generate an access violation.
+
+	  The tradeoff is performance impact, on a single CPU system kernel
+	  compilation sees a 3% slowdown, other systems and workloads may vary
+	  and you are advised to test this feature on your expected workload
+	  before deploying it.
+
+	  The slab sanitization feature excludes a few slab caches per default
+	  for performance reasons.  To extend the feature to cover those as
+	  well, pass "pax_sanitize_slab=full" as kernel command line parameter.
+
+	  To reduce the performance penalty by sanitizing pages only, albeit
+	  limiting the effectiveness of this feature at the same time, slab
+	  sanitization can be disabled with the kernel command line parameter
+	  "pax_sanitize_slab=off".
+
+	  Note that this feature does not protect data stored in live pages,
+	  e.g., process memory swapped to disk may stay there for a long time.
+
+config PAX_MEMORY_STACKLEAK
+	bool "Sanitize kernel stack"
+	default y if (GRKERNSEC_CONFIG_AUTO && GRKERNSEC_CONFIG_PRIORITY_SECURITY)
+	depends on X86 && GCC_PLUGINS
+	help
+	  By saying Y here the kernel will erase the kernel stack before it
+	  returns from a system call.  This in turn reduces the information
+	  that a kernel stack leak bug can reveal.
+
+	  Note that such a bug can still leak information that was put on
+	  the stack by the current system call (the one eventually triggering
+	  the bug) but traces of earlier system calls on the kernel stack
+	  cannot leak anymore.
+
+	  The tradeoff is performance impact: on a single CPU system kernel
+	  compilation sees a 1% slowdown, other systems and workloads may vary
+	  and you are advised to test this feature on your expected workload
+	  before deploying it.
+
+	  Note that the full feature requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.  Using
+	  older gcc versions means that functions with large enough stack
+	  frames may leave uninitialized memory behind that may be exposed
+	  to a later syscall leaking the stack.
+
+config PAX_MEMORY_STRUCTLEAK
+	bool "Forcibly initialize local variables copied to userland"
+	default y if (GRKERNSEC_CONFIG_AUTO && GRKERNSEC_CONFIG_PRIORITY_SECURITY)
+	depends on GCC_PLUGINS
+	help
+	  By saying Y here the kernel will zero initialize some local
+	  variables that are going to be copied to userland.  This in
+	  turn prevents unintended information leakage from the kernel
+	  stack should later code forget to explicitly set all parts of
+	  the copied variable.
+
+	  The tradeoff is less performance impact than PAX_MEMORY_STACKLEAK
+	  at a much smaller coverage.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+config PAX_MEMORY_UDEREF
+	bool "Prevent invalid userland pointer dereference"
+	default y if GRKERNSEC_CONFIG_AUTO && !(X86_64 && GRKERNSEC_CONFIG_PRIORITY_PERF) && !(X86_64 && GRKERNSEC_CONFIG_VIRT_HOST && GRKERNSEC_CONFIG_VIRT_VIRTUALBOX) && (!X86 || GRKERNSEC_CONFIG_VIRT_NONE || GRKERNSEC_CONFIG_VIRT_EPT)
+	depends on (X86 || (ARM && (CPU_V6 || CPU_V6K || CPU_V7) && !ARM_LPAE)) && !UML_X86 && !XEN
+	select PAX_PER_CPU_PGD if X86_64
+	help
+	  By saying Y here the kernel will be prevented from dereferencing
+	  userland pointers in contexts where the kernel expects only kernel
+	  pointers.  This is both a useful runtime debugging feature and a
+	  security measure that prevents exploiting a class of kernel bugs.
+
+	  The tradeoff is that some virtualization solutions may experience
+	  a huge slowdown and therefore you should not enable this feature
+	  for kernels meant to run in such environments.  Whether a given VM
+	  solution is affected or not is best determined by simply trying it
+	  out, the performance impact will be obvious right on boot as this
+	  mechanism engages from very early on.  A good rule of thumb is that
+	  VMs running on CPUs without hardware virtualization support (i.e.,
+	  the majority of IA-32 CPUs) will likely experience the slowdown.
+
+	  On X86_64 the kernel will make use of PCID support when available
+	  (Intel's Westmere, Sandy Bridge, etc) for better security (default)
+	  or performance impact.  Pass pax_weakuderef on the kernel command
+	  line to choose the latter.
+
+config PAX_REFCOUNT
+	bool "Prevent various kernel object reference counter overflows"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on GRKERNSEC && ((ARM && (CPU_V6 || CPU_V6K || CPU_V7)) || MIPS || PPC || SPARC64 || X86)
+	help
+	  By saying Y here the kernel will detect and prevent overflowing
+	  various (but not all) kinds of object reference counters.  Such
+	  overflows can normally occur due to bugs only and are often, if
+	  not always, exploitable.
+
+	  The tradeoff is that data structures protected by an overflowed
+	  refcount will never be freed and therefore will leak memory.  Note
+	  that this leak also happens even without this protection but in
+	  that case the overflow can eventually trigger the freeing of the
+	  data structure while it is still being used elsewhere, resulting
+	  in the exploitable situation that this feature prevents.
+
+	  Since this has a negligible performance impact, you should enable
+	  this feature.
+
+config PAX_USERCOPY
+	bool "Harden memory copies between kernel and userland"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on GRKERNSEC && HAVE_ARCH_HARDENED_USERCOPY
+	select HARDENED_USERCOPY
+	help
+	  By saying Y here the kernel will enforce the size of heap objects
+	  when they are copied in either direction between the kernel and
+	  userland, even if only a part of the heap object is copied.
+
+	  Specifically, this checking prevents information leaking from the
+	  kernel heap during kernel to userland copies (if the kernel heap
+	  object is otherwise fully initialized) and prevents kernel heap
+	  overflows during userland to kernel copies.
+
+	  Note that the current implementation provides the strictest bounds
+	  checks for the SLUB allocator.
+
+	  Enabling this option also enables per-slab cache protection against
+	  data in a given cache being copied into/out of via userland
+	  accessors.  Though the whitelist of regions will be reduced over
+	  time, it notably protects important data structures like task structs.
+
+	  If frame pointers are enabled on x86, this option will also restrict
+	  copies into and out of the kernel stack to local variables within a
+	  single frame.
+
+	  Since this has a negligible performance impact, you should enable
+	  this feature.
+
+config PAX_CONSTIFY_PLUGIN
+	bool "Automatically constify eligible structures"
+	default y
+	depends on !UML && PAX_KERNEXEC && GCC_PLUGINS
+	help
+	  By saying Y here the compiler will automatically constify a class
+	  of types that contain only function pointers.  This reduces the
+	  kernel's attack surface and also produces a better memory layout.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	  Note that if some code really has to modify constified variables
+	  then the source code will have to be patched to allow it.  Examples
+	  can be found in PaX itself (the no_const attribute) and for some
+	  out-of-tree modules at http://www.grsecurity.net/~paxguy1/ .
+
+
+config PAX_USERCOPY_DEBUG
+	bool
+	depends on X86 && PAX_USERCOPY
+	default n
+
+config PAX_SIZE_OVERFLOW
+	bool "Prevent various integer overflows in function size parameters"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on GCC_PLUGINS
+	depends on !SPARC64 && !ARM64
+	help
+	  By saying Y here the kernel recomputes expressions of function
+	  arguments marked by a size_overflow attribute with double integer
+	  precision (DImode/TImode for 32/64 bit integer types).
+
+	  If the recomputed argument does not fit the original type then the
+	  event is logged. If the pax_size_overflow_report_only parameter is
+	  NOT passed on the kernel command line at boot then the triggering
+	  process will also be killed.
+
+	  Homepage: https://github.com/ephox-gcc-plugins/size_overflow
+	  Blog: http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+config PAX_SIZE_OVERFLOW_EXTRA
+	bool "Increase coverage of size overflow checking"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on PAX_SIZE_OVERFLOW
+	help
+	  By saying Y here the kernel will instrument more size argument
+	  calculations that off-line static analysis tracked back through
+	  indirect function calls, structure fields and global variables.
+
+	  This greatly increases coverage and thus security however there
+	  are also more false positives and the performance impact is higher
+	  as well.
+
+config PAX_INITIFY
+	bool "Free more kernel memory after init"
+	depends on GCC_PLUGINS
+	help
+	  The kernel has a mechanism to free up code and data memory that is
+	  only used during kernel or module initialization.  Enabling this
+	  feature will teach the compiler to find more such code and data
+	  that can be freed after initialization.
+
+config HAVE_PAX_INITIFY_INIT_EXIT
+	bool
+	depends on GCC_PLUGINS
+	help
+	  Move functions to the exit section if they are called by __init and
+	  __exit functions too.
+
+config PAX_INITIFY_INIT_EXIT
+	bool
+	depends on PAX_INITIFY && HAVE_PAX_INITIFY_INIT_EXIT
+
+config PAX_INITIFY_VERBOSE
+	bool "Free more kernel memory after init (verbose mode)"
+	depends on GCC_PLUGINS && PAX_INITIFY
+	help
+	  Print all initified strings and all functions which should be
+	  __init/__exit.
+
+	  Note that the candidates identified for __init/__exit markings
+	  depend on the current kernel configuration and thus should be
+	  verified manually before the source code is patched.
+
+config PAX_LATENT_ENTROPY
+	bool "Generate some entropy during boot and runtime"
+	default y if GRKERNSEC_CONFIG_AUTO
+	depends on GCC_PLUGINS
+	select GCC_PLUGIN_LATENT_ENTROPY
+	help
+	  By saying Y here the kernel will instrument some kernel code to
+	  extract some entropy from both original and artificially created
+	  program state.  This will help especially embedded systems where
+	  there is little 'natural' source of entropy normally.  The cost
+	  is some slowdown of the boot process (about 0.5%) and fork and
+	  irq processing.
+
+	  When pax_extra_latent_entropy is passed on the kernel command line,
+	  entropy will be extracted from up to the first 4GB of RAM while the
+	  runtime memory allocator is being initialized.  This costs even more
+	  slowdown of the boot process.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	  Note that entropy extracted this way is not cryptographically
+	  secure!
+
+config PAX_RAP
+	bool "Prevent code reuse attacks"
+	depends on X86_64 && GCC_PLUGINS
+	default y if GRKERNSEC_CONFIG_AUTO
+	help
+	  By saying Y here the kernel will check indirect control transfers
+	  in order to detect and prevent attacks that try to hijack control
+	  flow by overwriting code pointers.
+
+	  If you have an amd64 processor that does not support SMEP then you
+	  must also enable a KERNEXEC code pointer instrumentation method
+	  (see PAX_KERNEXEC_PLUGIN).
+
+	  Note that binary modules cannot be instrumented by this approach.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+endmenu
+
+endmenu
+
+source grsecurity/Kconfig
+
+endmenu
+
+endmenu
+
 source security/keys/Kconfig

 config SECURITY_DMESG_RESTRICT
@@ -104,7 +1164,7 @@ config INTEL_TXT
 config LSM_MMAP_MIN_ADDR
 	int "Low address space for LSM to protect from user allocation"
 	depends on SECURITY && SECURITY_SELINUX
-	default 32768 if ARM || (ARM64 && COMPAT)
+	default 32768 if ALPHA || ARM || (ARM64 && COMPAT) || PARISC || SPARC32
 	default 65536
 	help
 	  This is the portion of low virtual memory which should be protected
@@ -118,13 +1178,6 @@ config LSM_MMAP_MIN_ADDR
 	  this low address space will need the permission specific to the
 	  systems running LSM.

-config HAVE_HARDENED_USERCOPY_ALLOCATOR
-	bool
-	help
-	  The heap allocator implements __check_heap_object() for
-	  validating memory ranges against heap object sizes in
-	  support of CONFIG_HARDENED_USERCOPY.
-
 config HAVE_ARCH_HARDENED_USERCOPY
 	bool
 	help
@@ -134,23 +1187,14 @@ config HAVE_ARCH_HARDENED_USERCOPY
 	  copy_to_user() and copy_from_user().

 config HARDENED_USERCOPY
-	bool "Harden memory copies between kernel and userspace"
-	depends on HAVE_ARCH_HARDENED_USERCOPY
-	depends on HAVE_HARDENED_USERCOPY_ALLOCATOR
-	select BUG
-	help
-	  This option checks for obviously wrong memory regions when
-	  copying memory to/from the kernel (via copy_to_user() and
-	  copy_from_user() functions) by rejecting memory ranges that
-	  are larger than the specified heap object, span multiple
-	  separately allocates pages, are not on the process stack,
-	  or are part of the kernel text. This kills entire classes
-	  of heap overflow exploits and similar kernel memory exposures.
+	bool
+	select BUG if BROKEN_SECURITY

 config HARDENED_USERCOPY_PAGESPAN
 	bool "Refuse to copy allocations that span multiple pages"
 	depends on HARDENED_USERCOPY
 	depends on EXPERT
+	depends on BROKEN_SECURITY
 	help
 	  When a multi-page allocation is done without __GFP_COMP,
 	  hardened usercopy will reject attempts to copy it. There are,
@@ -205,4 +1249,3 @@ config DEFAULT_SECURITY
 	default "" if DEFAULT_SECURITY_DAC

 endmenu
-
diff --git a/security/apparmor/file.c b/security/apparmor/file.c
index 4d2af4b..608971a 100644
--- a/security/apparmor/file.c
+++ b/security/apparmor/file.c
@@ -349,8 +349,8 @@ static inline bool xindex_is_subset(u32 link, u32 target)
 int aa_path_link(struct aa_profile *profile, struct dentry *old_dentry,
 		 const struct path *new_dir, struct dentry *new_dentry)
 {
-	struct path link = { new_dir->mnt, new_dentry };
-	struct path target = { new_dir->mnt, old_dentry };
+	struct path link = { .mnt = new_dir->mnt, .dentry = new_dentry };
+	struct path target = { .mnt = new_dir->mnt, .dentry = old_dentry };
 	struct path_cond cond = {
 		d_backing_inode(old_dentry)->i_uid,
 		d_backing_inode(old_dentry)->i_mode
diff --git a/security/apparmor/include/policy.h b/security/apparmor/include/policy.h
index 52275f0..4c84202 100644
--- a/security/apparmor/include/policy.h
+++ b/security/apparmor/include/policy.h
@@ -134,7 +134,7 @@ struct aa_namespace {
 	struct aa_ns_acct acct;
 	struct aa_profile *unconfined;
 	struct list_head sub_ns;
-	atomic_t uniq_null;
+	atomic_unchecked_t uniq_null;
 	long uniq_id;

 	struct dentry *dents[AAFS_NS_SIZEOF];
diff --git a/security/apparmor/lsm.c b/security/apparmor/lsm.c
index 41b8cb1..411695c 100644
--- a/security/apparmor/lsm.c
+++ b/security/apparmor/lsm.c
@@ -176,7 +176,7 @@ static int common_perm_dir_dentry(int op, const struct path *dir,
 				  struct dentry *dentry, u32 mask,
 				  struct path_cond *cond)
 {
-	struct path path = { dir->mnt, dentry };
+	struct path path = { .mnt = dir->mnt, .dentry = dentry };

 	return common_perm(op, &path, mask, cond);
 }
@@ -306,8 +306,8 @@ static int apparmor_path_rename(const struct path *old_dir, struct dentry *old_d

 	profile = aa_current_profile();
 	if (!unconfined(profile)) {
-		struct path old_path = { old_dir->mnt, old_dentry };
-		struct path new_path = { new_dir->mnt, new_dentry };
+		struct path old_path = { .mnt = old_dir->mnt, .dentry = old_dentry };
+		struct path new_path = { .mnt = new_dir->mnt, .dentry = new_dentry };
 		struct path_cond cond = { d_backing_inode(old_dentry)->i_uid,
 					  d_backing_inode(old_dentry)->i_mode
 		};
@@ -656,11 +656,11 @@ static const struct kernel_param_ops param_ops_aalockpolicy = {
 	.get = param_get_aalockpolicy
 };

-static int param_set_audit(const char *val, struct kernel_param *kp);
-static int param_get_audit(char *buffer, struct kernel_param *kp);
+static int param_set_audit(const char *val, const struct kernel_param *kp);
+static int param_get_audit(char *buffer, const struct kernel_param *kp);

-static int param_set_mode(const char *val, struct kernel_param *kp);
-static int param_get_mode(char *buffer, struct kernel_param *kp);
+static int param_set_mode(const char *val, const struct kernel_param *kp);
+static int param_get_mode(char *buffer, const struct kernel_param *kp);

 /* Flag values, also controllable via /sys/module/apparmor/parameters
  * We define special types as we want to do additional mediation.
@@ -774,7 +774,7 @@ static int param_get_aauint(char *buffer, const struct kernel_param *kp)
 	return param_get_uint(buffer, kp);
 }

-static int param_get_audit(char *buffer, struct kernel_param *kp)
+static int param_get_audit(char *buffer, const struct kernel_param *kp)
 {
 	if (!policy_view_capable())
 		return -EPERM;
@@ -785,7 +785,7 @@ static int param_get_audit(char *buffer, struct kernel_param *kp)
 	return sprintf(buffer, "%s", audit_mode_names[aa_g_audit]);
 }

-static int param_set_audit(const char *val, struct kernel_param *kp)
+static int param_set_audit(const char *val, const struct kernel_param *kp)
 {
 	int i;
 	if (!policy_admin_capable())
@@ -807,7 +807,7 @@ static int param_set_audit(const char *val, struct kernel_param *kp)
 	return -EINVAL;
 }

-static int param_get_mode(char *buffer, struct kernel_param *kp)
+static int param_get_mode(char *buffer, const struct kernel_param *kp)
 {
 	if (!policy_admin_capable())
 		return -EPERM;
@@ -818,7 +818,7 @@ static int param_get_mode(char *buffer, struct kernel_param *kp)
 	return sprintf(buffer, "%s", aa_profile_mode_names[aa_g_profile_mode]);
 }

-static int param_set_mode(const char *val, struct kernel_param *kp)
+static int param_set_mode(const char *val, const struct kernel_param *kp)
 {
 	int i;
 	if (!policy_admin_capable())
diff --git a/security/apparmor/policy.c b/security/apparmor/policy.c
index 179e68d..48bd588 100644
--- a/security/apparmor/policy.c
+++ b/security/apparmor/policy.c
@@ -298,7 +298,7 @@ static struct aa_namespace *alloc_namespace(const char *prefix,
 	/* ns and ns->unconfined share ns->unconfined refcount */
 	ns->unconfined->ns = ns;

-	atomic_set(&ns->uniq_null, 0);
+	atomic_set_unchecked(&ns->uniq_null, 0);

 	return ns;

@@ -689,7 +689,7 @@ struct aa_profile *aa_new_null_profile(struct aa_profile *parent, int hat)
 {
 	struct aa_profile *profile = NULL;
 	char *name;
-	int uniq = atomic_inc_return(&parent->ns->uniq_null);
+	int uniq = atomic_inc_return_unchecked(&parent->ns->uniq_null);

 	/* freed below */
 	name = kmalloc(strlen(parent->base.hname) + 2 + 7 + 8, GFP_KERNEL);
diff --git a/security/commoncap.c b/security/commoncap.c
index 8df676f..77e2cb5 100644
--- a/security/commoncap.c
+++ b/security/commoncap.c
@@ -433,6 +433,32 @@ int get_vfs_caps_from_disk(const struct dentry *dentry, struct cpu_vfs_cap_data
 	return 0;
 }

+/* returns:
+	1 for suid privilege
+	2 for sgid privilege
+	3 for fscap privilege
+*/
+int is_privileged_binary(const struct dentry *dentry)
+{
+	struct cpu_vfs_cap_data capdata;
+	struct inode *inode = dentry->d_inode;
+
+	if (!inode || S_ISDIR(inode->i_mode))
+		return 0;
+
+	if (inode->i_mode & S_ISUID)
+		return 1;
+	if ((inode->i_mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP))
+		return 2;
+
+	if (!get_vfs_caps_from_disk(dentry, &capdata)) {
+		if (!cap_isclear(capdata.inheritable) || !cap_isclear(capdata.permitted))
+			return 3;
+	}
+
+	return 0;
+}
+
 /*
  * Attempt to get the on-exec apply capability sets for an executable file from
  * its xattrs and, if present, apply them to the proposed credentials being
@@ -631,6 +657,9 @@ int cap_bprm_secureexec(struct linux_binprm *bprm)
 	const struct cred *cred = current_cred();
 	kuid_t root_uid = make_kuid(cred->user_ns, 0);

+	if (gr_acl_enable_at_secure())
+		return 1;
+
 	if (!uid_eq(cred->uid, root_uid)) {
 		if (bprm->cap_effective)
 			return 1;
diff --git a/security/integrity/ima/ima.h b/security/integrity/ima/ima.h
index df7834a..be87c8d 100644
--- a/security/integrity/ima/ima.h
+++ b/security/integrity/ima/ima.h
@@ -130,8 +130,8 @@ int ima_init_template(void);
 extern spinlock_t ima_queue_lock;

 struct ima_h_table {
-	atomic_long_t len;	/* number of stored measurements in the list */
-	atomic_long_t violations;
+	atomic_long_unchecked_t len;	/* number of stored measurements in the list */
+	atomic_long_unchecked_t violations;
 	struct hlist_head queue[IMA_MEASURE_HTABLE_SIZE];
 };
 extern struct ima_h_table ima_htable;
diff --git a/security/integrity/ima/ima_api.c b/security/integrity/ima/ima_api.c
index d01a52f..512130e 100644
--- a/security/integrity/ima/ima_api.c
+++ b/security/integrity/ima/ima_api.c
@@ -138,7 +138,7 @@ void ima_add_violation(struct file *file, const unsigned char *filename,
 	int result;

 	/* can overflow, only indicator */
-	atomic_long_inc(&ima_htable.violations);
+	atomic_long_inc_unchecked(&ima_htable.violations);

 	result = ima_alloc_init_template(&event_data, &entry);
 	if (result < 0) {
diff --git a/security/integrity/ima/ima_fs.c b/security/integrity/ima/ima_fs.c
index 3df4690..59a419e 100644
--- a/security/integrity/ima/ima_fs.c
+++ b/security/integrity/ima/ima_fs.c
@@ -31,12 +31,12 @@ static DEFINE_MUTEX(ima_write_mutex);
 static int valid_policy = 1;
 #define TMPBUFLEN 12
 static ssize_t ima_show_htable_value(char __user *buf, size_t count,
-				     loff_t *ppos, atomic_long_t *val)
+				     loff_t *ppos, atomic_long_unchecked_t *val)
 {
 	char tmpbuf[TMPBUFLEN];
 	ssize_t len;

-	len = scnprintf(tmpbuf, TMPBUFLEN, "%li\n", atomic_long_read(val));
+	len = scnprintf(tmpbuf, TMPBUFLEN, "%li\n", atomic_long_read_unchecked(val));
 	return simple_read_from_buffer(buf, count, ppos, tmpbuf, len);
 }

diff --git a/security/integrity/ima/ima_queue.c b/security/integrity/ima/ima_queue.c
index 32f6ac0..8275005 100644
--- a/security/integrity/ima/ima_queue.c
+++ b/security/integrity/ima/ima_queue.c
@@ -84,7 +84,7 @@ static int ima_add_digest_entry(struct ima_template_entry *entry)
 	INIT_LIST_HEAD(&qe->later);
 	list_add_tail_rcu(&qe->later, &ima_measurements);

-	atomic_long_inc(&ima_htable.len);
+	atomic_long_inc_unchecked(&ima_htable.len);
 	key = ima_hash_key(entry->digest);
 	hlist_add_head_rcu(&qe->hnext, &ima_htable.queue[key]);
 	return 0;
diff --git a/security/integrity/integrity.h b/security/integrity/integrity.h
index 24520b4..b89448a 100644
--- a/security/integrity/integrity.h
+++ b/security/integrity/integrity.h
@@ -177,7 +177,7 @@ static inline void evm_load_x509(void)

 #ifdef CONFIG_INTEGRITY_AUDIT
 /* declarations */
-void integrity_audit_msg(int audit_msgno, struct inode *inode,
+void __nocapture(4) integrity_audit_msg(int audit_msgno, struct inode *inode,
 			 const unsigned char *fname, const char *op,
 			 const char *cause, int result, int info);
 #else
diff --git a/security/keys/internal.h b/security/keys/internal.h
index a705a7d..898c675 100644
--- a/security/keys/internal.h
+++ b/security/keys/internal.h
@@ -91,12 +91,16 @@ extern void key_type_put(struct key_type *ktype);

 extern int __key_link_begin(struct key *keyring,
 			    const struct keyring_index_key *index_key,
-			    struct assoc_array_edit **_edit);
+			    struct assoc_array_edit **_edit)
+			    __acquires(&keyring->sem)
+			    __acquires(&keyring_serialise_link_sem);
 extern int __key_link_check_live_key(struct key *keyring, struct key *key);
 extern void __key_link(struct key *key, struct assoc_array_edit **_edit);
 extern void __key_link_end(struct key *keyring,
 			   const struct keyring_index_key *index_key,
-			   struct assoc_array_edit *edit);
+			   struct assoc_array_edit *edit)
+			   __releases(&keyring->sem)
+			   __releases(&keyring_serialise_link_sem);

 extern key_ref_t find_key_to_update(key_ref_t keyring_ref,
 				    const struct keyring_index_key *index_key);
@@ -192,7 +196,7 @@ struct request_key_auth {
 	void			*callout_info;
 	size_t			callout_len;
 	pid_t			pid;
-};
+} __randomize_layout;

 extern struct key_type key_type_request_key_auth;
 extern struct key *request_key_auth_new(struct key *target,
diff --git a/security/keys/key.c b/security/keys/key.c
index 346fbf2..84458b1 100644
--- a/security/keys/key.c
+++ b/security/keys/key.c
@@ -287,7 +287,7 @@ struct key *key_alloc(struct key_type *type, const char *desc,

 	atomic_set(&key->usage, 1);
 	init_rwsem(&key->sem);
-	lockdep_set_class(&key->sem, &type->lock_class);
+	lockdep_set_class(&key->sem, (struct lock_class_key *)&type->lock_class);
 	key->index_key.type = type;
 	key->user = user;
 	key->quotalen = quotalen;
@@ -1101,7 +1101,9 @@ int register_key_type(struct key_type *ktype)
 	struct key_type *p;
 	int ret;

-	memset(&ktype->lock_class, 0, sizeof(ktype->lock_class));
+	pax_open_kernel();
+	memset((void *)&ktype->lock_class, 0, sizeof(ktype->lock_class));
+	pax_close_kernel();

 	ret = -EEXIST;
 	down_write(&key_types_sem);
@@ -1113,7 +1115,7 @@ int register_key_type(struct key_type *ktype)
 	}

 	/* store the type */
-	list_add(&ktype->link, &key_types_list);
+	pax_list_add((struct list_head *)&ktype->link, &key_types_list);

 	pr_notice("Key type %s registered\n", ktype->name);
 	ret = 0;
@@ -1135,7 +1137,7 @@ EXPORT_SYMBOL(register_key_type);
 void unregister_key_type(struct key_type *ktype)
 {
 	down_write(&key_types_sem);
-	list_del_init(&ktype->link);
+	pax_list_del_init((struct list_head *)&ktype->link);
 	downgrade_write(&key_types_sem);
 	key_gc_keytype(ktype);
 	pr_notice("Key type %s unregistered\n", ktype->name);
@@ -1153,10 +1155,10 @@ void __init key_init(void)
 			0, SLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);

 	/* add the special key types */
-	list_add_tail(&key_type_keyring.link, &key_types_list);
-	list_add_tail(&key_type_dead.link, &key_types_list);
-	list_add_tail(&key_type_user.link, &key_types_list);
-	list_add_tail(&key_type_logon.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_keyring.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_dead.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_user.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_logon.link, &key_types_list);

 	/* record the root user tracking */
 	rb_link_node(&root_key_user.node,
diff --git a/security/keys/keyctl.c b/security/keys/keyctl.c
index d580ad0..283a3ed 100644
--- a/security/keys/keyctl.c
+++ b/security/keys/keyctl.c
@@ -99,7 +99,7 @@ SYSCALL_DEFINE5(add_key, const char __user *, _type,

 	if (_payload) {
 		ret = -ENOMEM;
-		payload = kmalloc(plen, GFP_KERNEL | __GFP_NOWARN);
+		payload = kmalloc(plen, GFP_KERNEL | GFP_USERCOPY | __GFP_NOWARN);
 		if (!payload) {
 			if (plen <= PAGE_SIZE)
 				goto error2;
@@ -324,7 +324,7 @@ long keyctl_update_key(key_serial_t id,
 	payload = NULL;
 	if (_payload) {
 		ret = -ENOMEM;
-		payload = kmalloc(plen, GFP_KERNEL);
+		payload = kmalloc(plen, GFP_KERNEL | GFP_USERCOPY);
 		if (!payload)
 			goto error;

@@ -616,7 +616,7 @@ long keyctl_describe_key(key_serial_t keyid,

 	/* calculate how much information we're going to return */
 	ret = -ENOMEM;
-	infobuf = kasprintf(GFP_KERNEL,
+	infobuf = kasprintf(GFP_KERNEL | GFP_USERCOPY,
 			    "%s;%d;%d;%08x;",
 			    key->type->name,
 			    from_kuid_munged(current_user_ns(), key->uid),
@@ -1064,7 +1064,7 @@ long keyctl_instantiate_key_common(key_serial_t id,

 	if (from) {
 		ret = -ENOMEM;
-		payload = kmalloc(plen, GFP_KERNEL);
+		payload = kmalloc(plen, GFP_KERNEL | GFP_USERCOPY);
 		if (!payload) {
 			if (plen <= PAGE_SIZE)
 				goto error;
diff --git a/security/keys/keyring.c b/security/keys/keyring.c
index c91e4e0..d3193f6 100644
--- a/security/keys/keyring.c
+++ b/security/keys/keyring.c
@@ -1095,8 +1095,6 @@ static int keyring_detect_cycle(struct key *A, struct key *B)
 int __key_link_begin(struct key *keyring,
 		     const struct keyring_index_key *index_key,
 		     struct assoc_array_edit **_edit)
-	__acquires(&keyring->sem)
-	__acquires(&keyring_serialise_link_sem)
 {
 	struct assoc_array_edit *edit;
 	int ret;
@@ -1196,8 +1194,6 @@ void __key_link(struct key *key, struct assoc_array_edit **_edit)
 void __key_link_end(struct key *keyring,
 		    const struct keyring_index_key *index_key,
 		    struct assoc_array_edit *edit)
-	__releases(&keyring->sem)
-	__releases(&keyring_serialise_link_sem)
 {
 	BUG_ON(index_key->type == NULL);
 	kenter("%d,%s,", keyring->serial, index_key->type->name);
diff --git a/security/min_addr.c b/security/min_addr.c
index f728728..6457a0c 100644
--- a/security/min_addr.c
+++ b/security/min_addr.c
@@ -14,6 +14,7 @@ unsigned long dac_mmap_min_addr = CONFIG_DEFAULT_MMAP_MIN_ADDR;
  */
 static void update_mmap_min_addr(void)
 {
+#ifndef SPARC
 #ifdef CONFIG_LSM_MMAP_MIN_ADDR
 	if (dac_mmap_min_addr > CONFIG_LSM_MMAP_MIN_ADDR)
 		mmap_min_addr = dac_mmap_min_addr;
@@ -22,6 +23,7 @@ static void update_mmap_min_addr(void)
 #else
 	mmap_min_addr = dac_mmap_min_addr;
 #endif
+#endif
 }

 /*
diff --git a/security/selinux/avc.c b/security/selinux/avc.c
index e60c79d..41fb721 100644
--- a/security/selinux/avc.c
+++ b/security/selinux/avc.c
@@ -71,7 +71,7 @@ struct avc_xperms_node {
 struct avc_cache {
 	struct hlist_head	slots[AVC_CACHE_SLOTS]; /* head for avc_node->list */
 	spinlock_t		slots_lock[AVC_CACHE_SLOTS]; /* lock for writes */
-	atomic_t		lru_hint;	/* LRU hint for reclaim scan */
+	atomic_unchecked_t	lru_hint;	/* LRU hint for reclaim scan */
 	atomic_t		active_nodes;
 	u32			latest_notif;	/* latest revocation notification */
 };
@@ -183,7 +183,7 @@ void __init avc_init(void)
 		spin_lock_init(&avc_cache.slots_lock[i]);
 	}
 	atomic_set(&avc_cache.active_nodes, 0);
-	atomic_set(&avc_cache.lru_hint, 0);
+	atomic_set_unchecked(&avc_cache.lru_hint, 0);

 	avc_node_cachep = kmem_cache_create("avc_node", sizeof(struct avc_node),
 					0, SLAB_PANIC, NULL);
@@ -521,7 +521,7 @@ static inline int avc_reclaim_node(void)
 	spinlock_t *lock;

 	for (try = 0, ecx = 0; try < AVC_CACHE_SLOTS; try++) {
-		hvalue = atomic_inc_return(&avc_cache.lru_hint) & (AVC_CACHE_SLOTS - 1);
+		hvalue = atomic_inc_return_unchecked(&avc_cache.lru_hint) & (AVC_CACHE_SLOTS - 1);
 		head = &avc_cache.slots[hvalue];
 		lock = &avc_cache.slots_lock[hvalue];

diff --git a/security/selinux/include/xfrm.h b/security/selinux/include/xfrm.h
index 1450f85..a91e0bc 100644
--- a/security/selinux/include/xfrm.h
+++ b/security/selinux/include/xfrm.h
@@ -48,7 +48,7 @@ static inline void selinux_xfrm_notify_policyload(void)

 	rtnl_lock();
 	for_each_net(net) {
-		atomic_inc(&net->xfrm.flow_cache_genid);
+		atomic_inc_unchecked(&net->xfrm.flow_cache_genid);
 		rt_genid_bump_all(net);
 	}
 	rtnl_unlock();
diff --git a/security/tomoyo/file.c b/security/tomoyo/file.c
index 7041a58..223f21f 100644
--- a/security/tomoyo/file.c
+++ b/security/tomoyo/file.c
@@ -692,7 +692,7 @@ int tomoyo_path_number_perm(const u8 type, const struct path *path,
 {
 	struct tomoyo_request_info r;
 	struct tomoyo_obj_info obj = {
-		.path1 = *path,
+		.path1 = { .mnt = path->mnt, .dentry = path->dentry },
 	};
 	int error = -ENOMEM;
 	struct tomoyo_path_info buf;
@@ -740,7 +740,7 @@ int tomoyo_check_open_permission(struct tomoyo_domain_info *domain,
 	struct tomoyo_path_info buf;
 	struct tomoyo_request_info r;
 	struct tomoyo_obj_info obj = {
-		.path1 = *path,
+		.path1 = { .mnt = path->mnt, .dentry = path->dentry },
 	};
 	int idx;

@@ -786,7 +786,7 @@ int tomoyo_path_perm(const u8 operation, const struct path *path, const char *ta
 {
 	struct tomoyo_request_info r;
 	struct tomoyo_obj_info obj = {
-		.path1 = *path,
+		.path1 = { .mnt = path->mnt, .dentry = path->dentry },
 	};
 	int error;
 	struct tomoyo_path_info buf;
@@ -843,7 +843,7 @@ int tomoyo_mkdev_perm(const u8 operation, const struct path *path,
 {
 	struct tomoyo_request_info r;
 	struct tomoyo_obj_info obj = {
-		.path1 = *path,
+		.path1 = { .mnt = path->mnt, .dentry = path->dentry },
 	};
 	int error = -ENOMEM;
 	struct tomoyo_path_info buf;
@@ -890,8 +890,8 @@ int tomoyo_path2_perm(const u8 operation, const struct path *path1,
 	struct tomoyo_path_info buf2;
 	struct tomoyo_request_info r;
 	struct tomoyo_obj_info obj = {
-		.path1 = *path1,
-		.path2 = *path2,
+		.path1 = { .mnt = path1->mnt, .dentry = path1->dentry },
+		.path2 = { .mnt = path2->mnt, .dentry = path2->dentry }
 	};
 	int idx;

diff --git a/security/tomoyo/mount.c b/security/tomoyo/mount.c
index 14b53fb..8829296 100644
--- a/security/tomoyo/mount.c
+++ b/security/tomoyo/mount.c
@@ -118,6 +118,10 @@ static int tomoyo_mount_acl(struct tomoyo_request_info *r,
 		   type == tomoyo_mounts[TOMOYO_MOUNT_MOVE]) {
 		need_dev = -1; /* dev_name is a directory */
 	} else {
+		if (!capable(CAP_SYS_ADMIN)) {
+			error = -EPERM;
+			goto out;
+		}
 		fstype = get_fs_type(type);
 		if (!fstype) {
 			error = -ENODEV;
diff --git a/security/tomoyo/tomoyo.c b/security/tomoyo/tomoyo.c
index 75c9987..b9569d4 100644
--- a/security/tomoyo/tomoyo.c
+++ b/security/tomoyo/tomoyo.c
@@ -165,7 +165,7 @@ static int tomoyo_path_truncate(const struct path *path)
  */
 static int tomoyo_path_unlink(const struct path *parent, struct dentry *dentry)
 {
-	struct path path = { parent->mnt, dentry };
+	struct path path = { .mnt = parent->mnt, .dentry = dentry };
 	return tomoyo_path_perm(TOMOYO_TYPE_UNLINK, &path, NULL);
 }

@@ -181,7 +181,7 @@ static int tomoyo_path_unlink(const struct path *parent, struct dentry *dentry)
 static int tomoyo_path_mkdir(const struct path *parent, struct dentry *dentry,
 			     umode_t mode)
 {
-	struct path path = { parent->mnt, dentry };
+	struct path path = { .mnt = parent->mnt, .dentry = dentry };
 	return tomoyo_path_number_perm(TOMOYO_TYPE_MKDIR, &path,
 				       mode & S_IALLUGO);
 }
@@ -196,7 +196,7 @@ static int tomoyo_path_mkdir(const struct path *parent, struct dentry *dentry,
  */
 static int tomoyo_path_rmdir(const struct path *parent, struct dentry *dentry)
 {
-	struct path path = { parent->mnt, dentry };
+	struct path path = { .mnt = parent->mnt, .dentry = dentry };
 	return tomoyo_path_perm(TOMOYO_TYPE_RMDIR, &path, NULL);
 }

@@ -212,7 +212,7 @@ static int tomoyo_path_rmdir(const struct path *parent, struct dentry *dentry)
 static int tomoyo_path_symlink(const struct path *parent, struct dentry *dentry,
 			       const char *old_name)
 {
-	struct path path = { parent->mnt, dentry };
+	struct path path = { .mnt = parent->mnt, .dentry = dentry };
 	return tomoyo_path_perm(TOMOYO_TYPE_SYMLINK, &path, old_name);
 }

@@ -229,7 +229,7 @@ static int tomoyo_path_symlink(const struct path *parent, struct dentry *dentry,
 static int tomoyo_path_mknod(const struct path *parent, struct dentry *dentry,
 			     umode_t mode, unsigned int dev)
 {
-	struct path path = { parent->mnt, dentry };
+	struct path path = { .mnt = parent->mnt, .dentry = dentry };
 	int type = TOMOYO_TYPE_CREATE;
 	const unsigned int perm = mode & S_IALLUGO;

@@ -268,8 +268,8 @@ static int tomoyo_path_mknod(const struct path *parent, struct dentry *dentry,
 static int tomoyo_path_link(struct dentry *old_dentry, const struct path *new_dir,
 			    struct dentry *new_dentry)
 {
-	struct path path1 = { new_dir->mnt, old_dentry };
-	struct path path2 = { new_dir->mnt, new_dentry };
+	struct path path1 = { .mnt = new_dir->mnt, .dentry = old_dentry };
+	struct path path2 = { .mnt = new_dir->mnt, .dentry = new_dentry };
 	return tomoyo_path2_perm(TOMOYO_TYPE_LINK, &path1, &path2);
 }

@@ -288,8 +288,8 @@ static int tomoyo_path_rename(const struct path *old_parent,
 			      const struct path *new_parent,
 			      struct dentry *new_dentry)
 {
-	struct path path1 = { old_parent->mnt, old_dentry };
-	struct path path2 = { new_parent->mnt, new_dentry };
+	struct path path1 = { .mnt = old_parent->mnt, .dentry = old_dentry };
+	struct path path2 = { .mnt = new_parent->mnt, .dentry = new_dentry };
 	return tomoyo_path2_perm(TOMOYO_TYPE_RENAME, &path1, &path2);
 }

@@ -417,7 +417,7 @@ static int tomoyo_sb_mount(const char *dev_name, const struct path *path,
  */
 static int tomoyo_sb_umount(struct vfsmount *mnt, int flags)
 {
-	struct path path = { mnt, mnt->mnt_root };
+	struct path path = { .mnt = mnt, .dentry = mnt->mnt_root };
 	return tomoyo_path_perm(TOMOYO_TYPE_UMOUNT, &path, NULL);
 }

diff --git a/security/yama/Kconfig b/security/yama/Kconfig
index 90c605e..bf3a29a 100644
--- a/security/yama/Kconfig
+++ b/security/yama/Kconfig
@@ -1,6 +1,6 @@
 config SECURITY_YAMA
 	bool "Yama support"
-	depends on SECURITY
+	depends on SECURITY && !GRKERNSEC
 	default n
 	help
 	  This selects Yama, which extends DAC support with additional
diff --git a/security/yama/yama_lsm.c b/security/yama/yama_lsm.c
index 0309f21..0c9bdfb 100644
--- a/security/yama/yama_lsm.c
+++ b/security/yama/yama_lsm.c
@@ -425,7 +425,7 @@ static struct security_hook_list yama_hooks[] = {
 static int yama_dointvec_minmax(struct ctl_table *table, int write,
 				void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table table_copy;
+	ctl_table_no_const table_copy;

 	if (write && !capable(CAP_SYS_PTRACE))
 		return -EPERM;
