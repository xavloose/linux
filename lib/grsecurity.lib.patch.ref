diff --git a/lib/842/842_compress.c b/lib/842/842_compress.c
index 4051339..7144fad 100644
--- a/lib/842/842_compress.c
+++ b/lib/842/842_compress.c
@@ -306,7 +306,7 @@ static int add_template(struct sw842_param *p, u8 c)
 	}

 	if (sw842_template_counts)
-		atomic_inc(&template_count[t[4]]);
+		atomic_inc_unchecked(&template_count[t[4]]);

 	return 0;
 }
@@ -328,7 +328,7 @@ static int add_repeat_template(struct sw842_param *p, u8 r)
 		return ret;

 	if (sw842_template_counts)
-		atomic_inc(&template_repeat_count);
+		atomic_inc_unchecked(&template_repeat_count);

 	return 0;
 }
@@ -355,7 +355,7 @@ static int add_short_data_template(struct sw842_param *p, u8 b)
 	}

 	if (sw842_template_counts)
-		atomic_inc(&template_short_data_count);
+		atomic_inc_unchecked(&template_short_data_count);

 	return 0;
 }
@@ -368,7 +368,7 @@ static int add_zeros_template(struct sw842_param *p)
 		return ret;

 	if (sw842_template_counts)
-		atomic_inc(&template_zeros_count);
+		atomic_inc_unchecked(&template_zeros_count);

 	return 0;
 }
@@ -381,7 +381,7 @@ static int add_end_template(struct sw842_param *p)
 		return ret;

 	if (sw842_template_counts)
-		atomic_inc(&template_end_count);
+		atomic_inc_unchecked(&template_end_count);

 	return 0;
 }
diff --git a/lib/842/842_debugfs.h b/lib/842/842_debugfs.h
index e7f3bff..77d1d92 100644
--- a/lib/842/842_debugfs.h
+++ b/lib/842/842_debugfs.h
@@ -7,7 +7,7 @@
 static bool sw842_template_counts;
 module_param_named(template_counts, sw842_template_counts, bool, 0444);

-static atomic_t template_count[OPS_MAX], template_repeat_count,
+static atomic_unchecked_t template_count[OPS_MAX], template_repeat_count,
 	template_zeros_count, template_short_data_count, template_end_count;

 static struct dentry *sw842_debugfs_root;
@@ -28,16 +28,16 @@ static int __init sw842_debugfs_create(void)
 		char name[32];

 		snprintf(name, 32, "template_%02x", i);
-		debugfs_create_atomic_t(name, m, sw842_debugfs_root,
+		debugfs_create_atomic_unchecked_t(name, m, sw842_debugfs_root,
 					&template_count[i]);
 	}
-	debugfs_create_atomic_t("template_repeat", m, sw842_debugfs_root,
+	debugfs_create_atomic_unchecked_t("template_repeat", m, sw842_debugfs_root,
 				&template_repeat_count);
-	debugfs_create_atomic_t("template_zeros", m, sw842_debugfs_root,
+	debugfs_create_atomic_unchecked_t("template_zeros", m, sw842_debugfs_root,
 				&template_zeros_count);
-	debugfs_create_atomic_t("template_short_data", m, sw842_debugfs_root,
+	debugfs_create_atomic_unchecked_t("template_short_data", m, sw842_debugfs_root,
 				&template_short_data_count);
-	debugfs_create_atomic_t("template_end", m, sw842_debugfs_root,
+	debugfs_create_atomic_unchecked_t("template_end", m, sw842_debugfs_root,
 				&template_end_count);

 	return 0;
diff --git a/lib/842/842_decompress.c b/lib/842/842_decompress.c
index 11fc39b..e5cfa58 100644
--- a/lib/842/842_decompress.c
+++ b/lib/842/842_decompress.c
@@ -263,7 +263,7 @@ static int do_op(struct sw842_param *p, u8 o)
 	}

 	if (sw842_template_counts)
-		atomic_inc(&template_count[o]);
+		atomic_inc_unchecked(&template_count[o]);

 	return 0;
 }
@@ -331,7 +331,7 @@ int sw842_decompress(const u8 *in, unsigned int ilen,
 			}

 			if (sw842_template_counts)
-				atomic_inc(&template_repeat_count);
+				atomic_inc_unchecked(&template_repeat_count);

 			break;
 		case OP_ZEROS:
@@ -343,7 +343,7 @@ int sw842_decompress(const u8 *in, unsigned int ilen,
 			p.olen -= 8;

 			if (sw842_template_counts)
-				atomic_inc(&template_zeros_count);
+				atomic_inc_unchecked(&template_zeros_count);

 			break;
 		case OP_SHORT_DATA:
@@ -364,12 +364,12 @@ int sw842_decompress(const u8 *in, unsigned int ilen,
 			}

 			if (sw842_template_counts)
-				atomic_inc(&template_short_data_count);
+				atomic_inc_unchecked(&template_short_data_count);

 			break;
 		case OP_END:
 			if (sw842_template_counts)
-				atomic_inc(&template_end_count);
+				atomic_inc_unchecked(&template_end_count);

 			break;
 		default: /* use template */
diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug
index a6c8db1..8ff38cd 100644
--- a/lib/Kconfig.debug
+++ b/lib/Kconfig.debug
@@ -244,6 +244,7 @@ config PAGE_OWNER
 	bool "Track page owner"
 	depends on DEBUG_KERNEL && STACKTRACE_SUPPORT
 	select DEBUG_FS
+	depends on !GRKERNSEC_KMEM
 	select STACKTRACE
 	select STACKDEPOT
 	select PAGE_EXTENSION
@@ -260,6 +261,7 @@ config PAGE_OWNER
 config DEBUG_FS
 	bool "Debug Filesystem"
 	select SRCU
+	depends on !GRKERNSEC_KMEM
 	help
 	  debugfs is a virtual file system that kernel developers use to put
 	  debugging files into.  Enable this option to be able to read and
@@ -513,6 +515,7 @@ config DEBUG_KMEMLEAK
 	bool "Kernel memory leak detector"
 	depends on DEBUG_KERNEL && HAVE_DEBUG_KMEMLEAK
 	select DEBUG_FS
+	depends on !GRKERNSEC_KMEM
 	select STACKTRACE if STACKTRACE_SUPPORT
 	select KALLSYMS
 	select CRC32
@@ -712,6 +715,7 @@ config KCOV
 	select DEBUG_FS
 	select GCC_PLUGINS if !COMPILE_TEST
 	select GCC_PLUGIN_SANCOV if !COMPILE_TEST
+	depends on !GRKERNSEC_KMEM
 	help
 	  KCOV exposes kernel code coverage information in a form suitable
 	  for coverage-guided fuzzing (randomized testing).
@@ -1013,7 +1017,7 @@ config DEBUG_MUTEXES

 config DEBUG_WW_MUTEX_SLOWPATH
 	bool "Wait/wound mutex debugging: Slowpath testing"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select DEBUG_LOCK_ALLOC
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
@@ -1030,7 +1034,7 @@ config DEBUG_WW_MUTEX_SLOWPATH

 config DEBUG_LOCK_ALLOC
 	bool "Lock debugging: detect incorrect freeing of live locks"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
 	select LOCKDEP
@@ -1044,7 +1048,7 @@ config DEBUG_LOCK_ALLOC

 config PROVE_LOCKING
 	bool "Lock debugging: prove locking correctness"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select LOCKDEP
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
@@ -1098,7 +1102,7 @@ config LOCKDEP

 config LOCK_STAT
 	bool "Lock usage statistics"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select LOCKDEP
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
@@ -1511,6 +1515,7 @@ config NOTIFIER_ERROR_INJECTION
 	tristate "Notifier error injection"
 	depends on DEBUG_KERNEL
 	select DEBUG_FS
+	depends on !GRKERNSEC_KMEM
 	help
 	  This option provides the ability to inject artificial errors to
 	  specified notifier chain callbacks. It is useful to test the error
@@ -1656,6 +1661,7 @@ config FAIL_MMC_REQUEST
 config FAIL_FUTEX
 	bool "Fault-injection capability for futexes"
 	select DEBUG_FS
+	depends on !GRKERNSEC_KMEM
 	depends on FAULT_INJECTION && FUTEX
 	help
 	  Provide fault-injection capability for futexes.
@@ -1680,6 +1686,7 @@ config LATENCYTOP
 	depends on DEBUG_KERNEL
 	depends on STACKTRACE_SUPPORT
 	depends on PROC_FS
+	depends on !GRKERNSEC_HIDESYM
 	select FRAME_POINTER if !MIPS && !PPC && !S390 && !MICROBLAZE && !ARM_UNWIND && !ARC
 	select KALLSYMS
 	select KALLSYMS_ALL
@@ -1834,7 +1841,7 @@ endmenu # runtime tests

 config PROVIDE_OHCI1394_DMA_INIT
 	bool "Remote debugging over FireWire early on boot"
-	depends on PCI && X86
+	depends on PCI && X86 && !GRKERNSEC
 	help
 	  If you want to debug problems which hang or crash the kernel early
 	  on boot and the crashing machine has a FireWire port, you can use
diff --git a/lib/Kconfig.kmemcheck b/lib/Kconfig.kmemcheck
index 846e039..63ef284 100644
--- a/lib/Kconfig.kmemcheck
+++ b/lib/Kconfig.kmemcheck
@@ -10,6 +10,7 @@ menuconfig KMEMCHECK
 	depends on SLUB || SLAB
 	depends on !CC_OPTIMIZE_FOR_SIZE
 	depends on !FUNCTION_TRACER
+	depends on !PAX_INITIFY
 	select FRAME_POINTER
 	select STACKTRACE
 	default n
diff --git a/lib/Makefile b/lib/Makefile
index 50144a3..21d91da 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -76,7 +76,7 @@ obj-$(CONFIG_BTREE) += btree.o
 obj-$(CONFIG_INTERVAL_TREE) += interval_tree.o
 obj-$(CONFIG_ASSOCIATIVE_ARRAY) += assoc_array.o
 obj-$(CONFIG_DEBUG_PREEMPT) += smp_processor_id.o
-obj-$(CONFIG_DEBUG_LIST) += list_debug.o
+obj-y += list_debug.o
 obj-$(CONFIG_DEBUG_OBJECTS) += debugobjects.o

 ifneq ($(CONFIG_HAVE_DEC_LOCK),y)
diff --git a/lib/bitmap.c b/lib/bitmap.c
index 0b66f0e..58f3aef 100644
--- a/lib/bitmap.c
+++ b/lib/bitmap.c
@@ -363,7 +363,7 @@ int __bitmap_parse(const char *buf, unsigned int buflen,
 {
 	int c, old_c, totaldigits, ndigits, nchunks, nbits;
 	u32 chunk;
-	const char __user __force *ubuf = (const char __user __force *)buf;
+	const char __user *ubuf = (const char __force_user *)buf;

 	bitmap_zero(maskp, nmaskbits);

@@ -449,7 +449,7 @@ int bitmap_parse_user(const char __user *ubuf,
 {
 	if (!access_ok(VERIFY_READ, ubuf, ulen))
 		return -EFAULT;
-	return __bitmap_parse((const char __force *)ubuf,
+	return __bitmap_parse((const char __force_kernel *)ubuf,
 				ulen, 1, maskp, nmaskbits);

 }
@@ -515,7 +515,7 @@ static int __bitmap_parselist(const char *buf, unsigned int buflen,
 	unsigned int a, b, old_a, old_b;
 	unsigned int group_size, used_size;
 	int c, old_c, totaldigits, ndigits;
-	const char __user __force *ubuf = (const char __user __force *)buf;
+	const char __user *ubuf = (const char __force_user *)buf;
 	int at_start, in_range, in_partial_range;

 	totaldigits = c = 0;
@@ -655,7 +655,7 @@ int bitmap_parselist_user(const char __user *ubuf,
 {
 	if (!access_ok(VERIFY_READ, ubuf, ulen))
 		return -EFAULT;
-	return __bitmap_parselist((const char __force *)ubuf,
+	return __bitmap_parselist((const char __force_kernel *)ubuf,
 					ulen, 1, maskp, nmaskbits);
 }
 EXPORT_SYMBOL(bitmap_parselist_user);
diff --git a/lib/bug.c b/lib/bug.c
index bc3656e..470f3ab 100644
--- a/lib/bug.c
+++ b/lib/bug.c
@@ -148,6 +148,8 @@ enum bug_trap_type report_bug(unsigned long bugaddr, struct pt_regs *regs)
 		return BUG_TRAP_TYPE_NONE;

 	bug = find_bug(bugaddr);
+	if (!bug)
+		return BUG_TRAP_TYPE_NONE;

 	file = NULL;
 	line = 0;
diff --git a/lib/debugobjects.c b/lib/debugobjects.c
index 056052dc..6f17c2e 100644
--- a/lib/debugobjects.c
+++ b/lib/debugobjects.c
@@ -288,7 +288,7 @@ static void debug_object_is_on_stack(void *addr, int onstack)
 	if (limit > 4)
 		return;

-	is_on_stack = object_is_on_stack(addr);
+	is_on_stack = object_starts_on_stack(addr);
 	if (is_on_stack == onstack)
 		return;

diff --git a/lib/decompress_bunzip2.c b/lib/decompress_bunzip2.c
index 0234361..41a411c 100644
--- a/lib/decompress_bunzip2.c
+++ b/lib/decompress_bunzip2.c
@@ -665,7 +665,8 @@ static int INIT start_bunzip(struct bunzip_data **bdp, void *inbuf, long len,

 	/* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of
 	   uncompressed data.  Allocate intermediate buffer for block. */
-	bd->dbufSize = 100000*(i-BZh0);
+	i -= BZh0;
+	bd->dbufSize = 100000 * i;

 	bd->dbuf = large_malloc(bd->dbufSize * sizeof(int));
 	if (!bd->dbuf)
diff --git a/lib/decompress_unlzma.c b/lib/decompress_unlzma.c
index ed7a1fd..44a1a62 100644
--- a/lib/decompress_unlzma.c
+++ b/lib/decompress_unlzma.c
@@ -39,10 +39,10 @@

 #define	MIN(a, b) (((a) < (b)) ? (a) : (b))

-static long long INIT read_int(unsigned char *ptr, int size)
+static unsigned long long INIT read_int(unsigned char *ptr, int size)
 {
 	int i;
-	long long ret = 0;
+	unsigned long long ret = 0;

 	for (i = 0; i < size; i++)
 		ret = (ret << 8) | ptr[size-i-1];
diff --git a/lib/div64.c b/lib/div64.c
index 7f34525..c53be4b 100644
--- a/lib/div64.c
+++ b/lib/div64.c
@@ -61,7 +61,7 @@ EXPORT_SYMBOL(__div64_32);
 #endif

 #ifndef div_s64_rem
-s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
+s64 __intentional_overflow(-1) div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
 {
 	u64 quotient;

@@ -132,7 +132,7 @@ EXPORT_SYMBOL(div64_u64_rem);
  * 'http://www.hackersdelight.org/hdcodetxt/divDouble.c.txt'
  */
 #ifndef div64_u64
-u64 div64_u64(u64 dividend, u64 divisor)
+u64 __intentional_overflow(-1) div64_u64(u64 dividend, u64 divisor)
 {
 	u32 high = divisor >> 32;
 	u64 quot;
diff --git a/lib/dma-debug.c b/lib/dma-debug.c
index 8971370..79eb3f27 100644
--- a/lib/dma-debug.c
+++ b/lib/dma-debug.c
@@ -990,7 +990,7 @@ static int dma_debug_device_change(struct notifier_block *nb, unsigned long acti

 void dma_debug_add_bus(struct bus_type *bus)
 {
-	struct notifier_block *nb;
+	notifier_block_no_const *nb;

 	if (dma_debug_disabled())
 		return;
@@ -1181,7 +1181,7 @@ static void check_for_stack(struct device *dev,
 		if (PageHighMem(page))
 			return;
 		addr = page_address(page) + offset;
-		if (object_is_on_stack(addr))
+		if (object_starts_on_stack(addr))
 			err_printk(dev, NULL, "DMA-API: device driver maps memory from stack [addr=%p]\n", addr);
 	} else {
 		/* Stack is vmalloced. */
@@ -1193,6 +1193,7 @@ static void check_for_stack(struct device *dev,

 			addr = (u8 *)current->stack + i * PAGE_SIZE + offset;
 			err_printk(dev, NULL, "DMA-API: device driver maps memory from stack [probable addr=%p]\n", addr);
+			dump_stack();
 			break;
 		}
 	}
diff --git a/lib/inflate.c b/lib/inflate.c
index 013a761..c28f3fc 100644
--- a/lib/inflate.c
+++ b/lib/inflate.c
@@ -269,7 +269,7 @@ static void free(void *where)
 		malloc_ptr = free_mem_ptr;
 }
 #else
-#define malloc(a) kmalloc(a, GFP_KERNEL)
+#define malloc(a) kmalloc((a), GFP_KERNEL)
 #define free(a) kfree(a)
 #endif

diff --git a/lib/ioremap.c b/lib/ioremap.c
index 86c8911..f5bfc34 100644
--- a/lib/ioremap.c
+++ b/lib/ioremap.c
@@ -75,7 +75,7 @@ static inline int ioremap_pmd_range(pud_t *pud, unsigned long addr,
 	unsigned long next;

 	phys_addr -= addr;
-	pmd = pmd_alloc(&init_mm, pud, addr);
+	pmd = pmd_alloc_kernel(&init_mm, pud, addr);
 	if (!pmd)
 		return -ENOMEM;
 	do {
@@ -101,7 +101,7 @@ static inline int ioremap_pud_range(pgd_t *pgd, unsigned long addr,
 	unsigned long next;

 	phys_addr -= addr;
-	pud = pud_alloc(&init_mm, pgd, addr);
+	pud = pud_alloc_kernel(&init_mm, pgd, addr);
 	if (!pud)
 		return -ENOMEM;
 	do {
diff --git a/lib/irq_poll.c b/lib/irq_poll.c
index 1d6565e8..effaf13 100644
--- a/lib/irq_poll.c
+++ b/lib/irq_poll.c
@@ -74,7 +74,7 @@ void irq_poll_complete(struct irq_poll *iop)
 }
 EXPORT_SYMBOL(irq_poll_complete);

-static void __latent_entropy irq_poll_softirq(struct softirq_action *h)
+static void __latent_entropy irq_poll_softirq(void)
 {
 	struct list_head *list = this_cpu_ptr(&blk_cpu_iopoll);
 	int rearm = 0, budget = irq_poll_budget;
diff --git a/lib/is_single_threaded.c b/lib/is_single_threaded.c
index 391fd23..96e17b6 100644
--- a/lib/is_single_threaded.c
+++ b/lib/is_single_threaded.c
@@ -22,6 +22,9 @@ bool current_is_single_threaded(void)
 	struct task_struct *p, *t;
 	bool ret;

+	if (!mm)
+		return true;
+
 	if (atomic_read(&task->signal->live) != 1)
 		return false;

diff --git a/lib/kobject.c b/lib/kobject.c
index 445dcae..cbfd25d 100644
--- a/lib/kobject.c
+++ b/lib/kobject.c
@@ -955,9 +955,9 @@ EXPORT_SYMBOL_GPL(kset_create_and_add);


 static DEFINE_SPINLOCK(kobj_ns_type_lock);
-static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES];
+static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES] __read_only;

-int kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
+int __init kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
 {
 	enum kobj_ns_type type = ops->type;
 	int error;
diff --git a/lib/list_debug.c b/lib/list_debug.c
index 3859bf6..38bdeaa 100644
--- a/lib/list_debug.c
+++ b/lib/list_debug.c
@@ -11,7 +11,9 @@
 #include <linux/bug.h>
 #include <linux/kernel.h>
 #include <linux/rculist.h>
+#include <linux/mm.h>

+#ifdef CONFIG_DEBUG_LIST
 /*
  * Insert a new entry between two known consecutive entries.
  *
@@ -19,21 +21,40 @@
  * the prev/next entries already!
  */

+static bool __list_add_debug(struct list_head *new,
+			     struct list_head *prev,
+			     struct list_head *next)
+{
+	if (unlikely(next->prev != prev)) {
+		printk(KERN_ERR "list_add corruption. next->prev should be "
+			"prev (%p), but was %p. (next=%p).\n",
+			prev, next->prev, next);
+		BUG();
+		return false;
+	}
+	if (unlikely(prev->next != next)) {
+		printk(KERN_ERR "list_add corruption. prev->next should be "
+			"next (%p), but was %p. (prev=%p).\n",
+			next, prev->next, prev);
+		BUG();
+		return false;
+	}
+	if (unlikely(new == prev || new == next)) {
+		printk(KERN_ERR "list_add double add: new=%p, prev=%p, next=%p.\n",
+			new, prev, next);
+		BUG();
+		return false;
+	}
+	return true;
+}
+
 void __list_add(struct list_head *new,
-			      struct list_head *prev,
-			      struct list_head *next)
+		struct list_head *prev,
+		struct list_head *next)
 {
-	WARN(next->prev != prev,
-		"list_add corruption. next->prev should be "
-		"prev (%p), but was %p. (next=%p).\n",
-		prev, next->prev, next);
-	WARN(prev->next != next,
-		"list_add corruption. prev->next should be "
-		"next (%p), but was %p. (prev=%p).\n",
-		next, prev->next, prev);
-	WARN(new == prev || new == next,
-	     "list_add double add: new=%p, prev=%p, next=%p.\n",
-	     new, prev, next);
+	if (!__list_add_debug(new, prev, next))
+		return;
+
 	next->prev = new;
 	new->next = next;
 	new->prev = prev;
@@ -41,28 +62,46 @@ void __list_add(struct list_head *new,
 }
 EXPORT_SYMBOL(__list_add);

-void __list_del_entry(struct list_head *entry)
+static bool __list_del_entry_debug(struct list_head *entry)
 {
 	struct list_head *prev, *next;

 	prev = entry->prev;
 	next = entry->next;

-	if (WARN(next == LIST_POISON1,
-		"list_del corruption, %p->next is LIST_POISON1 (%p)\n",
-		entry, LIST_POISON1) ||
-	    WARN(prev == LIST_POISON2,
-		"list_del corruption, %p->prev is LIST_POISON2 (%p)\n",
-		entry, LIST_POISON2) ||
-	    WARN(prev->next != entry,
-		"list_del corruption. prev->next should be %p, "
-		"but was %p\n", entry, prev->next) ||
-	    WARN(next->prev != entry,
-		"list_del corruption. next->prev should be %p, "
-		"but was %p\n", entry, next->prev))
+	if (unlikely(next == LIST_POISON1)) {
+		printk(KERN_ERR "list_del corruption, %p->next is LIST_POISON1 (%p)\n",
+			entry, LIST_POISON1);
+		BUG();
+		return false;
+	}
+	if (unlikely(prev == LIST_POISON2)) {
+		printk(KERN_ERR "list_del corruption, %p->prev is LIST_POISON2 (%p)\n",
+			entry, LIST_POISON2);
+		BUG();
+		return false;
+	}
+	if (unlikely(entry->prev->next != entry)) {
+		printk(KERN_ERR "list_del corruption. prev->next should be %p, "
+			"but was %p\n", entry, prev->next);
+		BUG();
+		return false;
+	}
+	if (unlikely(entry->next->prev != entry)) {
+		printk(KERN_ERR "list_del corruption. next->prev should be %p, "
+			"but was %p\n", entry, next->prev);
+		BUG();
+		return false;
+	}
+	return true;
+}
+
+void __list_del_entry(struct list_head *entry)
+{
+	if (!__list_del_entry_debug(entry))
 		return;

-	__list_del(prev, next);
+	__list_del(entry->prev, entry->next);
 }
 EXPORT_SYMBOL(__list_del_entry);

@@ -86,15 +125,84 @@ EXPORT_SYMBOL(list_del);
 void __list_add_rcu(struct list_head *new,
 		    struct list_head *prev, struct list_head *next)
 {
-	WARN(next->prev != prev,
-		"list_add_rcu corruption. next->prev should be prev (%p), but was %p. (next=%p).\n",
-		prev, next->prev, next);
-	WARN(prev->next != next,
-		"list_add_rcu corruption. prev->next should be next (%p), but was %p. (prev=%p).\n",
-		next, prev->next, prev);
+	if (!__list_add_debug(new, prev, next))
+		return;
+
 	new->next = next;
 	new->prev = prev;
 	rcu_assign_pointer(list_next_rcu(prev), new);
 	next->prev = new;
 }
 EXPORT_SYMBOL(__list_add_rcu);
+#endif
+
+void __pax_list_add(struct list_head *new, struct list_head *prev, struct list_head *next)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_add_debug(new, prev, next))
+		return;
+#endif
+
+	pax_open_kernel();
+	next->prev = new;
+	new->next = next;
+	new->prev = prev;
+	prev->next = new;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(__pax_list_add);
+
+void pax_list_del(struct list_head *entry)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_del_entry_debug(entry))
+		return;
+#endif
+
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	entry->next = LIST_POISON1;
+	entry->prev = LIST_POISON2;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del);
+
+void pax_list_del_init(struct list_head *entry)
+{
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	INIT_LIST_HEAD(entry);
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del_init);
+
+void __pax_list_add_rcu(struct list_head *new,
+			struct list_head *prev, struct list_head *next)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_add_debug(new, prev, next))
+		return;
+#endif
+
+	pax_open_kernel();
+	new->next = next;
+	new->prev = prev;
+	rcu_assign_pointer(list_next_rcu(prev), new);
+	next->prev = new;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(__pax_list_add_rcu);
+
+void pax_list_del_rcu(struct list_head *entry)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_del_entry_debug(entry))
+		return;
+#endif
+
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	entry->prev = LIST_POISON2;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del_rcu);
diff --git a/lib/llist.c b/lib/llist.c
index ae5872b..63a9698 100644
--- a/lib/llist.c
+++ b/lib/llist.c
@@ -25,6 +25,7 @@
 #include <linux/kernel.h>
 #include <linux/export.h>
 #include <linux/llist.h>
+#include <linux/mm.h>


 /**
@@ -48,6 +49,22 @@ bool llist_add_batch(struct llist_node *new_first, struct llist_node *new_last,
 }
 EXPORT_SYMBOL_GPL(llist_add_batch);

+bool pax_llist_add_batch(struct llist_node *new_first, struct llist_node *new_last,
+			 struct llist_head *head)
+{
+	struct llist_node *first;
+
+	do {
+		first = ACCESS_ONCE(head->first);
+		pax_open_kernel();
+		new_last->next = first;
+		pax_close_kernel();
+	} while (cmpxchg(&head->first, first, new_first) != first);
+
+	return !first;
+}
+EXPORT_SYMBOL_GPL(pax_llist_add_batch);
+
 /**
  * llist_del_first - delete the first entry of lock-less list
  * @head:	the head for your lock-less list
diff --git a/lib/lockref.c b/lib/lockref.c
index 5a92189..d77978d 100644
--- a/lib/lockref.c
+++ b/lib/lockref.c
@@ -40,13 +40,13 @@
 void lockref_get(struct lockref *lockref)
 {
 	CMPXCHG_LOOP(
-		new.count++;
+		__lockref_inc(&new);
 	,
 		return;
 	);

 	spin_lock(&lockref->lock);
-	lockref->count++;
+	__lockref_inc(lockref);
 	spin_unlock(&lockref->lock);
 }
 EXPORT_SYMBOL(lockref_get);
@@ -61,8 +61,8 @@ int lockref_get_not_zero(struct lockref *lockref)
 	int retval;

 	CMPXCHG_LOOP(
-		new.count++;
-		if (old.count <= 0)
+		__lockref_inc(&new);
+		if (__lockref_read(&old) <= 0)
 			return 0;
 	,
 		return 1;
@@ -70,8 +70,8 @@ int lockref_get_not_zero(struct lockref *lockref)

 	spin_lock(&lockref->lock);
 	retval = 0;
-	if (lockref->count > 0) {
-		lockref->count++;
+	if (__lockref_read(lockref) > 0) {
+		__lockref_inc(lockref);
 		retval = 1;
 	}
 	spin_unlock(&lockref->lock);
@@ -88,17 +88,17 @@ EXPORT_SYMBOL(lockref_get_not_zero);
 int lockref_get_or_lock(struct lockref *lockref)
 {
 	CMPXCHG_LOOP(
-		new.count++;
-		if (old.count <= 0)
+		__lockref_inc(&new);
+		if (__lockref_read(&old) <= 0)
 			break;
 	,
 		return 1;
 	);

 	spin_lock(&lockref->lock);
-	if (lockref->count <= 0)
+	if (__lockref_read(lockref) <= 0)
 		return 0;
-	lockref->count++;
+	__lockref_inc(lockref);
 	spin_unlock(&lockref->lock);
 	return 1;
 }
@@ -114,11 +114,11 @@ EXPORT_SYMBOL(lockref_get_or_lock);
 int lockref_put_return(struct lockref *lockref)
 {
 	CMPXCHG_LOOP(
-		new.count--;
-		if (old.count <= 0)
+		__lockref_dec(&new);
+		if (__lockref_read(&old) <= 0)
 			return -1;
 	,
-		return new.count;
+		return __lockref_read(&new);
 	);
 	return -1;
 }
@@ -132,17 +132,17 @@ EXPORT_SYMBOL(lockref_put_return);
 int lockref_put_or_lock(struct lockref *lockref)
 {
 	CMPXCHG_LOOP(
-		new.count--;
-		if (old.count <= 1)
+		__lockref_dec(&new);
+		if (__lockref_read(&old) <= 1)
 			break;
 	,
 		return 1;
 	);

 	spin_lock(&lockref->lock);
-	if (lockref->count <= 1)
+	if (__lockref_read(lockref) <= 1)
 		return 0;
-	lockref->count--;
+	__lockref_dec(lockref);
 	spin_unlock(&lockref->lock);
 	return 1;
 }
@@ -155,7 +155,7 @@ EXPORT_SYMBOL(lockref_put_or_lock);
 void lockref_mark_dead(struct lockref *lockref)
 {
 	assert_spin_locked(&lockref->lock);
-	lockref->count = -128;
+	__lockref_set(lockref, -128);
 }
 EXPORT_SYMBOL(lockref_mark_dead);

@@ -169,8 +169,8 @@ int lockref_get_not_dead(struct lockref *lockref)
 	int retval;

 	CMPXCHG_LOOP(
-		new.count++;
-		if (old.count < 0)
+		__lockref_inc(&new);
+		if (__lockref_read(&old) < 0)
 			return 0;
 	,
 		return 1;
@@ -178,8 +178,8 @@ int lockref_get_not_dead(struct lockref *lockref)

 	spin_lock(&lockref->lock);
 	retval = 0;
-	if (lockref->count >= 0) {
-		lockref->count++;
+	if (__lockref_read(lockref) >= 0) {
+		__lockref_inc(lockref);
 		retval = 1;
 	}
 	spin_unlock(&lockref->lock);
diff --git a/lib/nlattr.c b/lib/nlattr.c
index fce1e9a..d44559b 100644
--- a/lib/nlattr.c
+++ b/lib/nlattr.c
@@ -278,6 +278,8 @@ int nla_memcpy(void *dest, const struct nlattr *src, int count)
 {
 	int minlen = min_t(int, count, nla_len(src));

+	BUG_ON(minlen < 0);
+
 	memcpy(dest, nla_data(src), minlen);
 	if (count > minlen)
 		memset(dest + minlen, 0, count - minlen);
diff --git a/lib/percpu-refcount.c b/lib/percpu-refcount.c
index 9ac959e..6c94a5e 100644
--- a/lib/percpu-refcount.c
+++ b/lib/percpu-refcount.c
@@ -31,7 +31,7 @@
  * atomic_long_t can't hit 0 before we've added up all the percpu refs.
  */

-#define PERCPU_COUNT_BIAS	(1LU << (BITS_PER_LONG - 1))
+#define PERCPU_COUNT_BIAS	(1LU << (BITS_PER_LONG - 2))

 static DEFINE_SPINLOCK(percpu_ref_switch_lock);
 static DECLARE_WAIT_QUEUE_HEAD(percpu_ref_switch_waitq);
diff --git a/lib/radix-tree.c b/lib/radix-tree.c
index 8e6d552..3b33b84 100644
--- a/lib/radix-tree.c
+++ b/lib/radix-tree.c
@@ -67,7 +67,7 @@ struct radix_tree_preload {
 	/* nodes->private_data points to next preallocated node */
 	struct radix_tree_node *nodes;
 };
-static DEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads) = { 0, };
+static DEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads);

 static inline void *node_to_entry(void *ptr)
 {
diff --git a/lib/rbtree.c b/lib/rbtree.c
index eb8a19f..3cb9b61 100644
--- a/lib/rbtree.c
+++ b/lib/rbtree.c
@@ -412,7 +412,9 @@ static inline void dummy_copy(struct rb_node *old, struct rb_node *new) {}
 static inline void dummy_rotate(struct rb_node *old, struct rb_node *new) {}

 static const struct rb_augment_callbacks dummy_callbacks = {
-	dummy_propagate, dummy_copy, dummy_rotate
+	.propagate = dummy_propagate,
+	.copy = dummy_copy,
+	.rotate = dummy_rotate
 };

 void rb_insert_color(struct rb_node *node, struct rb_root *root)
diff --git a/lib/rhashtable.c b/lib/rhashtable.c
index 32d0ad0..7db49b5 100644
--- a/lib/rhashtable.c
+++ b/lib/rhashtable.c
@@ -651,8 +651,8 @@ EXPORT_SYMBOL_GPL(rhashtable_walk_exit);
  * will rewind back to the beginning and you may use it immediately
  * by calling rhashtable_walk_next.
  */
+int rhashtable_walk_start(struct rhashtable_iter *iter) __acquires(RCU);
 int rhashtable_walk_start(struct rhashtable_iter *iter)
-	__acquires(RCU)
 {
 	struct rhashtable *ht = iter->ht;

@@ -754,8 +754,8 @@ EXPORT_SYMBOL_GPL(rhashtable_walk_next);
  *
  * Finish a hash table walk.
  */
+void rhashtable_walk_stop(struct rhashtable_iter *iter) __releases(RCU);
 void rhashtable_walk_stop(struct rhashtable_iter *iter)
-	__releases(RCU)
 {
 	struct rhashtable *ht;
 	struct bucket_table *tbl = iter->walker.tbl;
diff --git a/lib/seq_buf.c b/lib/seq_buf.c
index cb18469..20ac511 100644
--- a/lib/seq_buf.c
+++ b/lib/seq_buf.c
@@ -259,7 +259,7 @@ int seq_buf_putmem_hex(struct seq_buf *s, const void *mem,
  */
 int seq_buf_path(struct seq_buf *s, const struct path *path, const char *esc)
 {
-	char *buf;
+	unsigned char *buf;
 	size_t size = seq_buf_get_buf(s, &buf);
 	int res = -1;

@@ -268,7 +268,7 @@ int seq_buf_path(struct seq_buf *s, const struct path *path, const char *esc)
 	if (size) {
 		char *p = d_path(path, buf, size);
 		if (!IS_ERR(p)) {
-			char *end = mangle_path(buf, p, esc);
+			unsigned char *end = mangle_path(buf, p, esc);
 			if (end)
 				res = end - buf;
 		}
diff --git a/lib/show_mem.c b/lib/show_mem.c
index 1feed6a..4ede1e9 100644
--- a/lib/show_mem.c
+++ b/lib/show_mem.c
@@ -47,6 +47,6 @@ void show_mem(unsigned int filter)
 		quicklist_total_size());
 #endif
 #ifdef CONFIG_MEMORY_FAILURE
-	printk("%lu pages hwpoisoned\n", atomic_long_read(&num_poisoned_pages));
+	printk("%lu pages hwpoisoned\n", atomic_long_read_unchecked(&num_poisoned_pages));
 #endif
 }
diff --git a/lib/strncpy_from_user.c b/lib/strncpy_from_user.c
index 7e35fc4..808ece4 100644
--- a/lib/strncpy_from_user.c
+++ b/lib/strncpy_from_user.c
@@ -24,7 +24,7 @@
  */
 static inline long do_strncpy_from_user(char *dst, const char __user *src, long count, unsigned long max)
 {
-	const struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;
+	static const struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;
 	long res = 0;

 	/*
diff --git a/lib/strnlen_user.c b/lib/strnlen_user.c
index 8e105ed..eefbbf9 100644
--- a/lib/strnlen_user.c
+++ b/lib/strnlen_user.c
@@ -26,7 +26,7 @@
  */
 static inline long do_strnlen_user(const char __user *src, unsigned long count, unsigned long max)
 {
-	const struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;
+	static const struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;
 	long align, res = 0;
 	unsigned long c;

diff --git a/lib/vsprintf.c b/lib/vsprintf.c
index 0967771..2871684 100644
--- a/lib/vsprintf.c
+++ b/lib/vsprintf.c
@@ -16,6 +16,9 @@
  * - scnprintf and vscnprintf
  */

+#ifdef CONFIG_GRKERNSEC_HIDESYM
+#define __INCLUDED_BY_HIDESYM 1
+#endif
 #include <stdarg.h>
 #include <linux/clk.h>
 #include <linux/clk-provider.h>
@@ -118,7 +121,7 @@ long long simple_strtoll(const char *cp, char **endp, unsigned int base)
 }
 EXPORT_SYMBOL(simple_strtoll);

-static noinline_for_stack
+static noinline_for_stack __nocapture(1) __unverified_nocapture(1)
 int skip_atoi(const char **s)
 {
 	int i = 0;
@@ -680,7 +683,7 @@ char *symbol_string(char *buf, char *end, void *ptr,
 #ifdef CONFIG_KALLSYMS
 	if (*fmt == 'B')
 		sprint_backtrace(sym, value);
-	else if (*fmt != 'f' && *fmt != 's')
+	else if (*fmt != 'f' && *fmt != 's' && *fmt != 'X')
 		sprint_symbol(sym, value);
 	else
 		sprint_symbol_no_offset(sym, value);
@@ -1470,7 +1473,11 @@ char *flags_string(char *buf, char *end, void *flags_ptr, const char *fmt)
 	return format_flags(buf, end, flags, names);
 }

-int kptr_restrict __read_mostly;
+#ifdef CONFIG_GRKERNSEC_HIDESYM
+int kptr_restrict __read_only = 1;
+#else
+int kptr_restrict __read_only;
+#endif

 /*
  * Show a '%p' thing.  A kernel extension is that the '%p' is followed
@@ -1481,8 +1488,10 @@ int kptr_restrict __read_mostly;
  *
  * - 'F' For symbolic function descriptor pointers with offset
  * - 'f' For simple symbolic function names without offset
+ * - 'X' For simple symbolic function names without offset approved for use with GRKERNSEC_HIDESYM
  * - 'S' For symbolic direct pointers with offset
  * - 's' For symbolic direct pointers without offset
+ * - 'A' For symbolic direct pointers with offset approved for use with GRKERNSEC_HIDESYM
  * - '[FfSs]R' as above with __builtin_extract_return_addr() translation
  * - 'B' For backtraced symbolic direct pointers with offset
  * - 'R' For decoded struct resource, e.g., [mem 0x0-0x1f 64bit pref]
@@ -1570,7 +1579,7 @@ int kptr_restrict __read_mostly;
  * function pointers are really function descriptors, which contain a
  * pointer to the real address.
  */
-static noinline_for_stack
+static noinline_for_stack __nocapture(1) __unverified_nocapture(1)
 char *pointer(const char *fmt, char *buf, char *end, void *ptr,
 	      struct printf_spec spec)
 {
@@ -1578,12 +1587,12 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,

 	if (!ptr && *fmt != 'K') {
 		/*
-		 * Print (null) with the same width as a pointer so it makes
+		 * Print (nil) with the same width as a pointer so it makes
 		 * tabular output look nice.
 		 */
 		if (spec.field_width == -1)
 			spec.field_width = default_width;
-		return string(buf, end, "(null)", spec);
+		return string(buf, end, "(nil)", spec);
 	}

 	switch (*fmt) {
@@ -1593,6 +1602,14 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,
 		/* Fallthrough */
 	case 'S':
 	case 's':
+#ifdef CONFIG_GRKERNSEC_HIDESYM
+		break;
+#else
+		return symbol_string(buf, end, ptr, spec, fmt);
+#endif
+	case 'X':
+		ptr = dereference_function_descriptor(ptr);
+	case 'A':
 	case 'B':
 		return symbol_string(buf, end, ptr, spec, fmt);
 	case 'R':
@@ -1657,6 +1674,8 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,
 			va_end(va);
 			return buf;
 		}
+	case 'P':
+		break;
 	case 'K':
 		switch (kptr_restrict) {
 		case 0:
@@ -1686,6 +1705,9 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,
 			 */
 			cred = current_cred();
 			if (!has_capability_noaudit(current, CAP_SYSLOG) ||
+#ifdef CONFIG_GRKERNSEC_HIDESYM
+			    !has_capability_noaudit(current, CAP_SYS_ADMIN) ||
+#endif
 			    !uid_eq(cred->euid, cred->uid) ||
 			    !gid_eq(cred->egid, cred->gid))
 				ptr = NULL;
@@ -1719,6 +1741,22 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,
 	case 'G':
 		return flags_string(buf, end, ptr, fmt);
 	}
+
+#ifdef CONFIG_GRKERNSEC_HIDESYM
+	/* 'P' = approved pointers to copy to userland,
+	   as in the /proc/kallsyms case, as we make it display nothing
+	   for non-root users, and the real contents for root users
+	   'X' = approved simple symbols
+	   Also ignore 'K' pointers, since we force their NULLing for non-root users
+	   above
+	*/
+	if ((unsigned long)ptr > TASK_SIZE && *fmt != 'P' && *fmt != 'X' && *fmt != 'K' && is_usercopy_object(buf)) {
+		printk(KERN_ALERT "grsec: kernel infoleak detected!  Please report this log to spender@grsecurity.net.\n");
+		dump_stack();
+		ptr = NULL;
+	}
+#endif
+
 	spec.flags |= SMALL;
 	if (spec.field_width == -1) {
 		spec.field_width = default_width;
@@ -1749,7 +1787,7 @@ char *pointer(const char *fmt, char *buf, char *end, void *ptr,
  * @precision: precision of a number
  * @qualifier: qualifier of a number (long, size_t, ...)
  */
-static noinline_for_stack
+static noinline_for_stack __nocapture(1)
 int format_decode(const char *fmt, struct printf_spec *spec)
 {
 	const char *start = fmt;
@@ -2419,11 +2457,11 @@ int bstr_printf(char *buf, size_t size, const char *fmt, const u32 *bin_buf)
 	typeof(type) value;						\
 	if (sizeof(type) == 8) {					\
 		args = PTR_ALIGN(args, sizeof(u32));			\
-		*(u32 *)&value = *(u32 *)args;				\
-		*((u32 *)&value + 1) = *(u32 *)(args + 4);		\
+		*(u32 *)&value = *(const u32 *)args;			\
+		*((u32 *)&value + 1) = *(const u32 *)(args + 4);	\
 	} else {							\
 		args = PTR_ALIGN(args, sizeof(type));			\
-		value = *(typeof(type) *)args;				\
+		value = *(const typeof(type) *)args;			\
 	}								\
 	args += sizeof(type);						\
 	value;								\
@@ -2486,7 +2524,7 @@ int bstr_printf(char *buf, size_t size, const char *fmt, const u32 *bin_buf)
 		case FORMAT_TYPE_STR: {
 			const char *str_arg = args;
 			args += strlen(str_arg) + 1;
-			str = string(str, end, (char *)str_arg, spec);
+			str = string(str, end, str_arg, spec);
 			break;
 		}
